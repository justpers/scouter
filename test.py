# test.py
from __future__ import print_function
import argparse
import torch
import torch.nn.functional as F
from torchvision import datasets, transforms
from PIL import Image
import numpy as np
import os
from timm.models import create_model

from sloter.utils.vis import apply_colormap_on_image
from sloter.slot_model import SlotModel
from train import get_args_parser

from dataset.ConText import ConText, MakeList, MakeListImage
from dataset.CUB200 import CUB_200


def test(args, model, device, image_orig, image_tensor, label, vis_id):
    """
    image_orig: PIL.Image (ì •ê·œí™” ì´ì „ ìƒíƒœ)
    image_tensor: torch.Tensor([C, H, W]) (ì •ê·œí™” í›„)
    """
    model.to(device)
    model.eval()

    # 1) Forward (slot attention í¬í•¨)
    image_tensor = image_tensor.to(device, dtype=torch.float32)
    output = model(image_tensor.unsqueeze(0))  # (1, num_classes)
    pred = output.argmax(dim=1, keepdim=True)
    print("Raw logits:", output[0].detach().cpu().numpy())
    print("Predicted class:", pred.item())

    # 2) ì‹œê°í™”ë¥¼ ìœ„í•´ ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ì €ì¥
    os.makedirs('sloter/vis', exist_ok=True)
    image_orig.save('sloter/vis/image.png')

    # 3) ê° ìŠ¬ë¡¯ë³„ë¡œ ìƒì„±ëœ ë§ˆìŠ¤í¬(slot_{id}.png)ë¥¼ ë¶ˆëŸ¬ì™€ heatmap ìƒì„±
    for slot_id in range(args.num_classes):
        # slot_{id}.pngëŠ” SlotAttention ë‚´ë¶€ì—ì„œ ì´ë¯¸ ìƒì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
        slot_path = f'sloter/vis/slot_{slot_id}.png'
        if not os.path.exists(slot_path):
            print(f"[Warning] {slot_path} ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. SlotAttention ì‹œê°í™”ê°€ ì œëŒ€ë¡œ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            continue

        # PILë¡œ ì¬ë¶ˆëŸ¬ì˜¤ê¸° â†’ numpy ë°°ì—´ë¡œ ë³€í™˜
        slot_mask = np.array(
            Image.open(slot_path).convert('L').resize(image_orig.size, resample=Image.BILINEAR),
            dtype=np.uint8
        )

        # ì›ë³¸ ì´ë¯¸ì§€ì—ë„ colormap ì ìš©
        heatmap_only, heatmap_on_image = apply_colormap_on_image(image_orig, slot_mask, 'jet')
        heatmap_only.save(f'sloter/vis/slot_heatmap_{slot_id}.png')
        heatmap_on_image.save(f'sloter/vis/slot_overlay_{slot_id}.png')


def main():
    parser = argparse.ArgumentParser('SCOUTER slot ì‹œê°í™”', parents=[get_args_parser()])
    parser.add_argument('--vis_target_class', type=int, default=0)
    args = parser.parse_args()

    # 1) ì¸ì íƒ€ì… ê³ ì •(convert strâ†’int/float)
    args_dict = vars(args)
    args_for_evaluation = ['num_classes', 'lambda_value', 'power', 'slots_per_class']
    args_type = [int, float, int, int]
    for idx, arg in enumerate(args_for_evaluation):
        args_dict[arg] = args_type[idx](args_dict[arg])

    # 2) ì‹œê°í™” ê²°ê³¼ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬
    os.makedirs('sloter/vis', exist_ok=True)

    # 3) checkpoint íŒŒì¼ëª… ìƒì„± ê·œì¹™
    checkpoint_path = args.output_dir

    # 4) ì¥ì¹˜ ì„¤ì •
    device = torch.device(args.device)

    # 5) â€œì •ê·œí™” ì „â€ â†’ â€œToTensor â†’ Normalizeâ€ ìˆœì„œë¡œ ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•œ transform
    base_transform = transforms.Compose([
        transforms.Resize((args.img_size, args.img_size)),
        transforms.ToTensor(),
    ])
    norm_transform = transforms.Compose([
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ])

    # if args.dataset == 'Blastocyst':
    #     # BlastocystëŠ” MakeListImage â†’ ConText(indexâ†’(path,label)) ë°©ì‹ ì‚¬ìš©
    #     train_list, val_list = MakeListImage(args).get_data()
    #     dataset_val = ConText(train_list, transform=base_transform)
    #     data_loader_val = torch.utils.data.DataLoader(
    #         dataset_val, batch_size=args.batch_size,
    #         shuffle=False, num_workers=1, pin_memory=True
    #     )
    #     # ì²« ë²ˆì§¸ ë°°ì¹˜ì—ì„œ ì´ë¯¸ì§€ í•œ ì¥ê³¼ ë ˆì´ë¸”ì„ ì¶”ì¶œ
    #     batch = next(iter(data_loader_val))
    #     image_tensor = batch["image"][3]      # ì•„ì§ Normalize ì ìš© ì „(Tensor([0,1]) ë²”ìœ„)
    #     label = batch["label"][3].item()
    #     image_orig = Image.fromarray(
    #         (image_tensor.cpu().numpy().transpose((1, 2, 0)) * 255).astype(np.uint8),
    #         mode='RGB'
    #     )
    #     # ì •ê·œí™” ì ìš©
    #     image_tensor = norm_transform(image_tensor)

    if args.dataset == 'Blastocyst':
    # ğŸ”¸ ì‹œê°í™”í•˜ê³  ì‹¶ì€ í´ë˜ìŠ¤ ì§€ì • (ì˜ˆ: class 1)
        vis_target_class = 0

        # BlastocystëŠ” MakeListImage â†’ ConText(indexâ†’(path,label)) ë°©ì‹ ì‚¬ìš©
        train_list, val_list = MakeListImage(args).get_data()
        dataset_val = ConText(train_list, transform=base_transform)
        data_loader_val = torch.utils.data.DataLoader(
            dataset_val, batch_size=args.batch_size,
            shuffle=False, num_workers=1, pin_memory=True
        )

        found = False
        for batch in data_loader_val:
            for i in range(len(batch["label"])):
                label_i = batch["label"][i].item()
                if label_i == vis_target_class:
                    image_tensor = batch["image"][i]  # Normalize ì „
                    label = label_i
                    image_orig = Image.fromarray(
                        (image_tensor.cpu().numpy().transpose((1, 2, 0)) * 255).astype(np.uint8),
                        mode='RGB'
                    )
                    image_tensor = norm_transform(image_tensor)
                    found = True
                    break
            if found:
                break

        if not found:
            raise ValueError(f"ğŸ’¥ í´ë˜ìŠ¤ {vis_target_class} ì´ë¯¸ì§€ë¥¼ ê²€ì¦ ë°ì´í„°ì…‹ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    elif args.dataset == 'ImageNet':
        # ImageNet ì—­ì‹œ MakeListImage â†’ ConText ë°©ì‹
        train_list, val_list = MakeListImage(args).get_data()
        dataset_val = ConText(val_list, transform=base_transform)
        data_loader_val = torch.utils.data.DataLoader(
            dataset_val, batch_size=args.batch_size,
            shuffle=False, num_workers=1, pin_memory=True
        )
        batch = next(iter(data_loader_val))
        image_tensor = batch["image"][0]
        label = batch["label"][0].item()
        image_orig = Image.fromarray(
            (image_tensor.cpu().numpy().transpose((1, 2, 0)) * 255).astype(np.uint8),
            mode='RGB'
        )
        image_tensor = norm_transform(image_tensor)

    elif args.dataset == 'ConText':
        # ConText(Chest X-ray)ë„ MakeList â†’ ConText ì‚¬ìš©
        train_list, val_list = MakeList(args).get_data()
        dataset_val = ConText(val_list, transform=base_transform)
        data_loader_val = torch.utils.data.DataLoader(
            dataset_val, batch_size=args.batch_size,
            shuffle=False, num_workers=1, pin_memory=True
        )
        batch = next(iter(data_loader_val))
        image_tensor = batch["image"][0]
        label = batch["label"][0].item()
        image_orig = Image.fromarray(
            (image_tensor.cpu().numpy().transpose((1, 2, 0)) * 255).astype(np.uint8),
            mode='RGB'
        )
        # ConText / Blastocyst / ImageNet ëª¨ë‘ ë™ì¼í•œ normalization ì‚¬ìš©
        image_tensor = norm_transform(image_tensor)

    elif args.dataset == 'MNIST':
        # MNIST: torchvision.datasets ì‚¬ìš©
        # (grayscale â†’ 1ì±„ë„ í…ì„œ)
        dataset_val = datasets.MNIST(
            './data/mnist', train=False,
            transform=transforms.Compose([
                transforms.Resize((args.img_size, args.img_size)),
                transforms.ToTensor(),
                transforms.Normalize((0.1307,), (0.3081,))
            ])
        )
        data_loader_val = torch.utils.data.DataLoader(
            dataset_val, batch_size=args.batch_size,
            shuffle=False, num_workers=1, pin_memory=True
        )
        image_tensor, _ = next(iter(data_loader_val))
        image_tensor = image_tensor[0]         # (1, H, W)
        label = 'N/A'                         # MNISTì—ì„  slot attention ì‹œê°í™” ì˜ë¯¸ ì—†ìŒ
        image_orig = Image.fromarray(
            (image_tensor.cpu().numpy()[0] * 255).astype(np.uint8),
            mode='L'
        )
        # MNIST normalizationì€ ì´ë¯¸ transform ë‚´ë¶€ì— ì ìš©ë¨

    elif args.dataset == 'CUB200':
        # CUB-200: custom CUB_200 í´ë˜ìŠ¤ ì‚¬ìš©
        dataset_val = CUB_200(args, train=False, transform=base_transform)
        data_loader_val = torch.utils.data.DataLoader(
            dataset_val, batch_size=args.batch_size,
            shuffle=False, num_workers=1, pin_memory=True
        )
        batch = next(iter(data_loader_val))
        image_tensor = batch["image"][0]
        label = batch["label"][0].item()
        image_orig = Image.fromarray(
            (image_tensor.cpu().numpy().transpose((1, 2, 0)) * 255).astype(np.uint8),
            mode='RGB'
        )
        image_tensor = norm_transform(image_tensor)

    else:
        raise ValueError(f"Unknown dataset: {args.dataset}")

    print("Ground-truth label:\t", label)

    # 7) ëª¨ë¸ ì´ˆê¸°í™” ë° ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    model = SlotModel(args)
    checkpoint = torch.load(checkpoint_path, map_location=args.device)
    print("Checkpoint keys:", list(checkpoint.keys()))
    model.load_state_dict(checkpoint["model"], strict=True)

    # 8) ì‹¤ì œ í…ŒìŠ¤íŠ¸/ì‹œê°í™” í˜¸ì¶œ
    test(args, model, device, image_orig, image_tensor, label, vis_id=args.vis_id)


if __name__ == '__main__':
    main()
