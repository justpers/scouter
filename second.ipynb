{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/home/work/SCOUTERv2/scouter'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting certifi==2020.6.20 (from -r requirements.txt (line 1))\n",
      "  Downloading certifi-2020.6.20-py2.py3-none-any.whl (156 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.6/156.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cycler==0.10.0 (from -r requirements.txt (line 2))\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.4.2)\n",
      "Collecting future==0.18.2 (from -r requirements.txt (line 4))\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.2/829.2 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting imageio==2.9.0 (from -r requirements.txt (line 5))\n",
      "  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: imgaug==0.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.4.0)\n",
      "Collecting joblib==0.16.0 (from -r requirements.txt (line 7))\n",
      "  Downloading joblib-0.16.0-py3-none-any.whl (300 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.8/300.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver==1.2.0 (from -r requirements.txt (line 8))\n",
      "  Downloading kiwisolver-1.2.0.tar.gz (52 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.1/52.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting matplotlib==3.3.1 (from -r requirements.txt (line 9))\n",
      "  Downloading matplotlib-3.3.1.tar.gz (38.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.8/38.8 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting networkx==2.5 (from -r requirements.txt (line 10))\n",
      "  Downloading networkx-2.5-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nose==1.3.7 (from -r requirements.txt (line 11))\n",
      "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy==1.21.6 (from -r requirements.txt (line 13))\n",
      "  Downloading numpy-1.21.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting opencv-python==4.5.5.64 (from -r requirements.txt (line 15))\n",
      "  Downloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting Pillow==7.2.0 (from -r requirements.txt (line 16))\n",
      "  Downloading Pillow-7.2.0.tar.gz (39.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.1/39.1 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting prefetch-generator==1.0.1 (from -r requirements.txt (line 17))\n",
      "  Downloading prefetch_generator-1.0.1.tar.gz (3.4 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting pyparsing==2.4.7 (from -r requirements.txt (line 18))\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-dateutil==2.8.1 (from -r requirements.txt (line 19))\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.2/227.2 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting PyWavelets==1.4.1 (from -r requirements.txt (line 21))\n",
      "  Downloading PyWavelets-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scikit-image==0.18.3 (from -r requirements.txt (line 23))\n",
      "  Downloading scikit-image-0.18.3.tar.gz (29.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.2/29.2 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting scikit-learn==1.0.2 (from -r requirements.txt (line 25))\n",
      "  Downloading scikit_learn-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scipy==1.7.3 (from -r requirements.txt (line 27))\n",
      "  Downloading scipy-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting Shapely==1.8.0 (from -r requirements.txt (line 29))\n",
      "  Downloading Shapely-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting six==1.15.0 (from -r requirements.txt (line 30))\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting tensorly==0.6.0 (from -r requirements.txt (line 32))\n",
      "  Downloading tensorly-0.6.0-py3-none-any.whl (160 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.8/160.8 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting thop==0.1.1.post2209072238 (from -r requirements.txt (line 33))\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Collecting threadpoolctl==2.1.0 (from -r requirements.txt (line 35))\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting tifffile==2020.9.3 (from -r requirements.txt (line 36))\n",
      "  Downloading tifffile-2020.9.3-py3-none-any.whl (148 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.4/148.4 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch==1.11.0 (from -r requirements.txt (line 38))\n",
      "  Downloading torch-1.11.0-cp310-cp310-manylinux1_x86_64.whl (750.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0mm0:01\u001b[0mm\n",
      "\u001b[?25hCollecting torchvision==0.12.0 (from -r requirements.txt (line 40))\n",
      "  Downloading torchvision-0.12.0-cp310-cp310-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm==4.49.0 (from -r requirements.txt (line 41))\n",
      "  Downloading tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.8/69.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.11.0->-r requirements.txt (line 38)) (4.9.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0->-r requirements.txt (line 40)) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0->-r requirements.txt (line 40)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0->-r requirements.txt (line 40)) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0->-r requirements.txt (line 40)) (2.0.7)\n",
      "Building wheels for collected packages: future, kiwisolver, matplotlib, Pillow, prefetch-generator, scikit-image\n",
      "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491058 sha256=702bd7af526e1e07f5976eb5ebf1cff55e2f61f584500f14715318846cc3cb81\n",
      "  Stored in directory: /home/work/.cache/pip/wheels/22/73/06/557dc4f4ef68179b9d763930d6eec26b88ed7c389b19588a1c\n",
      "  Building wheel for kiwisolver (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for kiwisolver: filename=kiwisolver-1.2.0-cp310-cp310-linux_x86_64.whl size=1146228 sha256=ba6e6152d0788fe169edb585f24a9da0a3a9b599544e0acffe62494ba575fdc0\n",
      "  Stored in directory: /home/work/.cache/pip/wheels/04/b8/14/9455223ef48e268c6a2f3f7845d222ed818c7dfbcebe4ff830\n",
      "  Building wheel for matplotlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for matplotlib: filename=matplotlib-3.3.1-cp310-cp310-linux_x86_64.whl size=11722502 sha256=f06d49f927d202ef87d1960b07e4afd48ace138056e572f6803fedeaa2115574\n",
      "  Stored in directory: /home/work/.cache/pip/wheels/fe/31/bd/cac116cfbdb888062d5f204ba245a2877cd025f5d33f03ae23\n",
      "  Building wheel for Pillow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for Pillow: filename=Pillow-7.2.0-cp310-cp310-linux_x86_64.whl size=1140124 sha256=21f9b30a01346db76c4d73c8df191711d7666d26a77c778c9f1c47dcbbdaa806\n",
      "  Stored in directory: /home/work/.cache/pip/wheels/fd/5c/a6/0ab3157e7e4a0ba139bd89cb1edbe0f87876cf55ef31b05d6a\n",
      "  Building wheel for prefetch-generator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for prefetch-generator: filename=prefetch_generator-1.0.1-py3-none-any.whl size=3941 sha256=e064d5c85a0949ab752b3db5474f507f846e6e55dad2ced51d93cbbacc42926c\n",
      "  Stored in directory: /home/work/.cache/pip/wheels/3d/20/e7/7a45ee9e97711b465664c3108f7045afaa0be105d783c553bc\n",
      "  Building wheel for scikit-image (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for scikit-image: filename=scikit_image-0.18.3-cp310-cp310-linux_x86_64.whl size=35357820 sha256=d73b6821845cd3b5084ee9fd440bfe3df69abf9aa7dcf4c63f99c5e41fbff156\n",
      "  Stored in directory: /home/work/.cache/pip/wheels/9d/55/80/c5bf730bc10906b1518cd6ebc05c87e69d1c46099ebdc9f59f\n",
      "Successfully built future kiwisolver matplotlib Pillow prefetch-generator scikit-image\n",
      "Installing collected packages: prefetch-generator, nose, certifi, tqdm, torch, threadpoolctl, six, Shapely, pyparsing, Pillow, numpy, networkx, kiwisolver, joblib, future, torchvision, tifffile, thop, scipy, PyWavelets, python-dateutil, opencv-python, imageio, cycler, tensorly, scikit-learn, matplotlib, scikit-image\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lida 0.0.10 requires fastapi, which is not installed.\n",
      "lida 0.0.10 requires kaleido, which is not installed.\n",
      "lida 0.0.10 requires python-multipart, which is not installed.\n",
      "lida 0.0.10 requires uvicorn, which is not installed.\n",
      "llmx 0.0.15a0 requires cohere, which is not installed.\n",
      "llmx 0.0.15a0 requires openai, which is not installed.\n",
      "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
      "arviz 0.15.1 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
      "bigframes 0.16.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.0.2 which is incompatible.\n",
      "fastai 2.7.13 requires pillow>=9.0.0, but you have pillow 7.2.0 which is incompatible.\n",
      "flax 0.7.5 requires numpy>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
      "google-colab 1.0.0 requires notebook==6.5.5, but you have notebook 7.1.2 which is incompatible.\n",
      "ibis-framework 6.2.0 requires python-dateutil<3,>=2.8.2, but you have python-dateutil 2.8.1 which is incompatible.\n",
      "imbalanced-learn 0.10.1 requires joblib>=1.1.1, but you have joblib 0.16.0 which is incompatible.\n",
      "jax 0.4.20 requires numpy>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
      "jax 0.4.20 requires scipy>=1.9, but you have scipy 1.7.3 which is incompatible.\n",
      "jaxlib 0.4.20+cuda12.cudnn89 requires numpy>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
      "jaxlib 0.4.20+cuda12.cudnn89 requires scipy>=1.9, but you have scipy 1.7.3 which is incompatible.\n",
      "jupyter-client 8.6.1 requires python-dateutil>=2.8.2, but you have python-dateutil 2.8.1 which is incompatible.\n",
      "mizani 0.9.3 requires matplotlib>=3.5.0, but you have matplotlib 3.3.1 which is incompatible.\n",
      "numba 0.58.1 requires numpy<1.27,>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
      "plotnine 0.12.4 requires matplotlib>=3.6.0, but you have matplotlib 3.3.1 which is incompatible.\n",
      "plotnine 0.12.4 requires numpy>=1.23.0, but you have numpy 1.21.6 which is incompatible.\n",
      "tensorflow 2.15.0 requires numpy<2.0.0,>=1.23.5, but you have numpy 1.21.6 which is incompatible.\n",
      "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\n",
      "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 1.11.0 which is incompatible.\n",
      "torchdata 0.7.0 requires torch==2.1.0, but you have torch 1.11.0 which is incompatible.\n",
      "torchtext 0.16.0 requires torch==2.1.0, but you have torch 1.11.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Pillow-7.2.0 PyWavelets-1.4.1 Shapely-1.8.0 certifi-2020.6.20 cycler-0.10.0 future-0.18.2 imageio-2.9.0 joblib-0.16.0 kiwisolver-1.2.0 matplotlib-3.3.1 networkx-2.5 nose-1.3.7 numpy-1.21.6 opencv-python-4.5.5.64 prefetch-generator-1.0.1 pyparsing-2.4.7 python-dateutil-2.8.1 scikit-image-0.18.3 scikit-learn-1.0.2 scipy-1.7.3 six-1.15.0 tensorly-0.6.0 thop-0.1.1.post2209072238 threadpoolctl-2.1.0 tifffile-2020.9.3 torch-1.11.0 torchvision-0.12.0 tqdm-4.49.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "PIL",
         "certifi",
         "cycler",
         "dateutil",
         "kiwisolver",
         "matplotlib",
         "mpl_toolkits",
         "numpy",
         "pyparsing",
         "six"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-image==0.18.3 in /home/work/.local/lib/python3.10/site-packages (0.18.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /home/work/.local/lib/python3.10/site-packages (from scikit-image==0.18.3) (1.21.6)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /home/work/.local/lib/python3.10/site-packages (from scikit-image==0.18.3) (1.7.3)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /home/work/.local/lib/python3.10/site-packages (from scikit-image==0.18.3) (3.3.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /home/work/.local/lib/python3.10/site-packages (from scikit-image==0.18.3) (2.5)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /home/work/.local/lib/python3.10/site-packages (from scikit-image==0.18.3) (7.2.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /home/work/.local/lib/python3.10/site-packages (from scikit-image==0.18.3) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/work/.local/lib/python3.10/site-packages (from scikit-image==0.18.3) (2020.9.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/work/.local/lib/python3.10/site-packages (from scikit-image==0.18.3) (1.4.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /home/work/.local/lib/python3.10/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.3) (2020.6.20)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/work/.local/lib/python3.10/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.3) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/work/.local/lib/python3.10/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.3) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/work/.local/lib/python3.10/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.3) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/work/.local/lib/python3.10/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.3) (2.8.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from networkx>=2.0->scikit-image==0.18.3) (4.4.2)\n",
      "Requirement already satisfied: six in /home/work/.local/lib/python3.10/site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.3) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scikit-image==0.18.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.21.6\n",
      "Uninstalling numpy-1.21.6:\n",
      "  Successfully uninstalled numpy-1.21.6\n",
      "Found existing installation: matplotlib 3.3.1\n",
      "Uninstalling matplotlib-3.3.1:\n",
      "  Successfully uninstalled matplotlib-3.3.1\n",
      "Found existing installation: scipy 1.7.3\n",
      "Uninstalling scipy-1.7.3:\n",
      "  Successfully uninstalled scipy-1.7.3\n",
      "Found existing installation: scikit-image 0.18.3\n",
      "Uninstalling scikit-image-0.18.3:\n",
      "  Successfully uninstalled scikit-image-0.18.3\n",
      "Found existing installation: PyWavelets 1.4.1\n",
      "Uninstalling PyWavelets-1.4.1:\n",
      "  Successfully uninstalled PyWavelets-1.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y numpy matplotlib scipy scikit-image PyWavelets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
      "Collecting matplotlib==3.6.3\n",
      "  Downloading matplotlib-3.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting scipy==1.9.3\n",
      "  Downloading scipy-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.7/33.7 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-image==0.19.3 in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
      "Collecting PyWavelets==1.4.1\n",
      "  Downloading PyWavelets-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.3) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/work/.local/lib/python3.10/site-packages (from matplotlib==3.6.3) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.3) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/work/.local/lib/python3.10/site-packages (from matplotlib==3.6.3) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.3) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/work/.local/lib/python3.10/site-packages (from matplotlib==3.6.3) (7.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/work/.local/lib/python3.10/site-packages (from matplotlib==3.6.3) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/work/.local/lib/python3.10/site-packages (from matplotlib==3.6.3) (2.8.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/work/.local/lib/python3.10/site-packages (from scikit-image==0.19.3) (2.5)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/work/.local/lib/python3.10/site-packages (from scikit-image==0.19.3) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/work/.local/lib/python3.10/site-packages (from scikit-image==0.19.3) (2020.9.3)\n",
      "Requirement already satisfied: six in /home/work/.local/lib/python3.10/site-packages (from cycler>=0.10->matplotlib==3.6.3) (1.15.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from networkx>=2.2->scikit-image==0.19.3) (4.4.2)\n",
      "Installing collected packages: scipy, PyWavelets, matplotlib\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lida 0.0.10 requires fastapi, which is not installed.\n",
      "lida 0.0.10 requires kaleido, which is not installed.\n",
      "lida 0.0.10 requires python-multipart, which is not installed.\n",
      "lida 0.0.10 requires uvicorn, which is not installed.\n",
      "bigframes 0.16.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.0.2 which is incompatible.\n",
      "fastai 2.7.13 requires pillow>=9.0.0, but you have pillow 7.2.0 which is incompatible.\n",
      "imbalanced-learn 0.10.1 requires joblib>=1.1.1, but you have joblib 0.16.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyWavelets-1.4.1 matplotlib-3.6.3 scipy-1.9.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "matplotlib",
         "mpl_toolkits"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install --no-cache-dir \\\n",
    "    numpy==1.23.5 \\\n",
    "    matplotlib==3.6.3 \\\n",
    "    scipy==1.9.3 \\\n",
    "    scikit-image==0.19.3 \\\n",
    "    PyWavelets==1.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files removed: 71\n"
     ]
    }
   ],
   "source": [
    "!pip cache purge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 1.11.0\n",
      "Uninstalling torch-1.11.0:\n",
      "  Successfully uninstalled torch-1.11.0\n",
      "Found existing installation: torchvision 0.12.0\n",
      "Uninstalling torchvision-0.12.0:\n",
      "  Successfully uninstalled torchvision-0.12.0\n",
      "Found existing installation: torchaudio 2.1.0+cu121\n",
      "Uninstalling torchaudio-2.1.0+cu121:\n",
      "\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/shutil.py\", line 816, in move\n",
      "    os.rename(src, real_dst)\n",
      "PermissionError: [Errno 13] Permission denied: '/usr/local/lib/python3.10/dist-packages/torchaudio-2.1.0+cu121.dist-info/' -> '/tmp/pip-uninstall-n2kyx3cr'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/uninstall.py\", line 105, in run\n",
      "    uninstall_pathset = req.uninstall(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/req/req_install.py\", line 680, in uninstall\n",
      "    uninstalled_pathset.remove(auto_confirm, verbose)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/req/req_uninstall.py\", line 381, in remove\n",
      "    moved.stash(path)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/req/req_uninstall.py\", line 272, in stash\n",
      "    renames(path, new_path)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/misc.py\", line 313, in renames\n",
      "    shutil.move(old, new)\n",
      "  File \"/usr/lib/python3.10/shutil.py\", line 834, in move\n",
      "    rmtree(src)\n",
      "  File \"/usr/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/usr/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/usr/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "PermissionError: [Errno 13] Permission denied: 'RECORD'\u001b[0m\u001b[31m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch==2.1.0+cu118\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.1.0%2Bcu118-cp310-cp310-linux_x86_64.whl (2325.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m777.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hCollecting torchvision==0.16.0+cu118\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.16.0%2Bcu118-cp310-cp310-linux_x86_64.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torchaudio==2.1.0 in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu118) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu118) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu118) (1.12)\n",
      "Requirement already satisfied: networkx in /home/work/.local/lib/python3.10/site-packages (from torch==2.1.0+cu118) (2.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu118) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu118) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu118) (2.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0+cu118) (1.23.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0+cu118) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/work/.local/lib/python3.10/site-packages (from torchvision==0.16.0+cu118) (7.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0+cu118) (2.1.3)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from networkx->torch==2.1.0+cu118) (4.4.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0+cu118) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0+cu118) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0+cu118) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/work/.local/lib/python3.10/site-packages (from requests->torchvision==0.16.0+cu118) (2020.6.20)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0+cu118) (1.3.0)\n",
      "Installing collected packages: torch, torchvision\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastai 2.7.13 requires pillow>=9.0.0, but you have pillow 7.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.1.0+cu118 torchvision-0.16.0+cu118\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall torch torchvision torchaudio -y\n",
    "\n",
    "!pip install torch==2.1.0+cu118 torchvision==0.16.0+cu118 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using distributed mode\n",
      "Start training: epochs=30, batch_size=16, lr=0.0005\n",
      "start train :0\n",
      "100% 28/28 [00:08<00:00,  3.13it/s]\n",
      "[Epoch 0] val_acc=0.547 val_auc=0.473 val_loss=5.567\n",
      "✔ best.pth updated\n",
      "train loss: [6.928]\n",
      "val loss: [5.567]\n",
      "train acc: [0.158]\n",
      "val acc: [0.547]\n",
      "train CE loss [0.0]\n",
      "val CE loss [5.567]\n",
      "train attention loss [0.0]\n",
      "val attention loss [0.0]\n",
      "start train :1\n",
      "100% 28/28 [00:08<00:00,  3.21it/s]\n",
      "[Epoch 1] val_acc=0.432 val_auc=0.491 val_loss=6.559\n",
      "train loss: [6.928, 6.48]\n",
      "val loss: [5.567, 6.559]\n",
      "train acc: [0.158, 0.435]\n",
      "val acc: [0.547, 0.432]\n",
      "train CE loss [0.0, 0.0]\n",
      "val CE loss [5.567, 6.559]\n",
      "train attention loss [0.0, 0.0]\n",
      "val attention loss [0.0, 0.0]\n",
      "start train :2\n",
      "100% 28/28 [00:08<00:00,  3.21it/s]\n",
      "[Epoch 2] val_acc=0.537 val_auc=0.499 val_loss=6.559\n",
      "train loss: [6.928, 6.48, 6.305]\n",
      "val loss: [5.567, 6.559, 6.559]\n",
      "train acc: [0.158, 0.435, 0.562]\n",
      "val acc: [0.547, 0.432, 0.537]\n",
      "train CE loss [0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559]\n",
      "train attention loss [0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0]\n",
      "start train :3\n",
      "100% 28/28 [00:08<00:00,  3.24it/s]\n",
      "[Epoch 3] val_acc=0.505 val_auc=0.557 val_loss=6.677\n",
      "train loss: [6.928, 6.48, 6.305, 6.202]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0]\n",
      "start train :4\n",
      "100% 28/28 [00:08<00:00,  3.23it/s]\n",
      "[Epoch 4] val_acc=0.600 val_auc=0.521 val_loss=6.295\n",
      "Epoch 00005: reducing learning rate of group 0 to 2.5000e-04.\n",
      "✔ best.pth updated\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :5\n",
      "100% 28/28 [00:08<00:00,  3.25it/s]\n",
      "[Epoch 5] val_acc=0.505 val_auc=0.502 val_loss=6.613\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :6\n",
      "100% 28/28 [00:08<00:00,  3.23it/s]\n",
      "[Epoch 6] val_acc=0.558 val_auc=0.580 val_loss=6.337\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :7\n",
      "100% 28/28 [00:08<00:00,  3.21it/s]\n",
      "[Epoch 7] val_acc=0.547 val_auc=0.580 val_loss=6.454\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :8\n",
      "100% 28/28 [00:08<00:00,  3.22it/s]\n",
      "[Epoch 8] val_acc=0.642 val_auc=0.646 val_loss=6.254\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.2500e-04.\n",
      "✔ best.pth updated\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774, 5.727]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77, 0.777]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547, 0.642]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :9\n",
      "100% 28/28 [00:08<00:00,  3.23it/s]\n",
      "[Epoch 9] val_acc=0.589 val_auc=0.597 val_loss=6.336\n",
      "→ saved checkpoint: checkpoint_0009.pth\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774, 5.727, 5.68]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77, 0.777, 0.804]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547, 0.642, 0.589]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :10\n",
      "100% 28/28 [00:08<00:00,  3.21it/s]\n",
      "[Epoch 10] val_acc=0.568 val_auc=0.612 val_loss=6.324\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774, 5.727, 5.68, 5.567]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77, 0.777, 0.804, 0.859]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547, 0.642, 0.589, 0.568]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :11\n",
      "100% 28/28 [00:08<00:00,  3.23it/s]\n",
      "[Epoch 11] val_acc=0.653 val_auc=0.618 val_loss=6.318\n",
      "✔ best.pth updated\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774, 5.727, 5.68, 5.567, 5.559]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77, 0.777, 0.804, 0.859, 0.85]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547, 0.642, 0.589, 0.568, 0.653]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :12\n",
      "100% 28/28 [00:08<00:00,  3.22it/s]\n",
      "[Epoch 12] val_acc=0.632 val_auc=0.625 val_loss=6.279\n",
      "Epoch 00013: reducing learning rate of group 0 to 6.2500e-05.\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774, 5.727, 5.68, 5.567, 5.559, 5.467]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77, 0.777, 0.804, 0.859, 0.85, 0.886]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547, 0.642, 0.589, 0.568, 0.653, 0.632]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :13\n",
      "100% 28/28 [00:08<00:00,  3.19it/s]\n",
      "[Epoch 13] val_acc=0.642 val_auc=0.633 val_loss=6.166\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774, 5.727, 5.68, 5.567, 5.559, 5.467, 5.43]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77, 0.777, 0.804, 0.859, 0.85, 0.886, 0.904]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547, 0.642, 0.589, 0.568, 0.653, 0.632, 0.642]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :14\n",
      "100% 28/28 [00:08<00:00,  3.24it/s]\n",
      "[Epoch 14] val_acc=0.653 val_auc=0.631 val_loss=6.215\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774, 5.727, 5.68, 5.567, 5.559, 5.467, 5.43, 5.462]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77, 0.777, 0.804, 0.859, 0.85, 0.886, 0.904, 0.9]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547, 0.642, 0.589, 0.568, 0.653, 0.632, 0.642, 0.653]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :15\n",
      "100% 28/28 [00:08<00:00,  3.23it/s]\n",
      "[Epoch 15] val_acc=0.663 val_auc=0.662 val_loss=6.179\n",
      "✔ best.pth updated\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774, 5.727, 5.68, 5.567, 5.559, 5.467, 5.43, 5.462, 5.434]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215, 6.179]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77, 0.777, 0.804, 0.859, 0.85, 0.886, 0.904, 0.9, 0.895]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547, 0.642, 0.589, 0.568, 0.653, 0.632, 0.642, 0.653, 0.663]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215, 6.179]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :16\n",
      "100% 28/28 [00:08<00:00,  3.23it/s]\n",
      "[Epoch 16] val_acc=0.674 val_auc=0.671 val_loss=6.134\n",
      "Epoch 00017: reducing learning rate of group 0 to 3.1250e-05.\n",
      "✔ best.pth updated\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774, 5.727, 5.68, 5.567, 5.559, 5.467, 5.43, 5.462, 5.434, 5.39]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215, 6.179, 6.134]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77, 0.777, 0.804, 0.859, 0.85, 0.886, 0.904, 0.9, 0.895, 0.924]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547, 0.642, 0.589, 0.568, 0.653, 0.632, 0.642, 0.653, 0.663, 0.674]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215, 6.179, 6.134]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :17\n",
      "100% 28/28 [00:08<00:00,  3.23it/s]\n",
      "[Epoch 17] val_acc=0.705 val_auc=0.680 val_loss=6.093\n",
      "✔ best.pth updated\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774, 5.727, 5.68, 5.567, 5.559, 5.467, 5.43, 5.462, 5.434, 5.39, 5.38]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215, 6.179, 6.134, 6.093]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77, 0.777, 0.804, 0.859, 0.85, 0.886, 0.904, 0.9, 0.895, 0.924, 0.933]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547, 0.642, 0.589, 0.568, 0.653, 0.632, 0.642, 0.653, 0.663, 0.674, 0.705]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215, 6.179, 6.134, 6.093]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :18\n",
      "100% 28/28 [00:08<00:00,  3.23it/s]\n",
      "[Epoch 18] val_acc=0.695 val_auc=0.675 val_loss=6.025\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774, 5.727, 5.68, 5.567, 5.559, 5.467, 5.43, 5.462, 5.434, 5.39, 5.38, 5.36]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215, 6.179, 6.134, 6.093, 6.025]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77, 0.777, 0.804, 0.859, 0.85, 0.886, 0.904, 0.9, 0.895, 0.924, 0.933, 0.94]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547, 0.642, 0.589, 0.568, 0.653, 0.632, 0.642, 0.653, 0.663, 0.674, 0.705, 0.695]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215, 6.179, 6.134, 6.093, 6.025]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :19\n",
      "100% 28/28 [00:08<00:00,  3.21it/s]\n",
      "[Epoch 19] val_acc=0.684 val_auc=0.665 val_loss=6.044\n",
      "→ saved checkpoint: checkpoint_0019.pth\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774, 5.727, 5.68, 5.567, 5.559, 5.467, 5.43, 5.462, 5.434, 5.39, 5.38, 5.36, 5.35]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215, 6.179, 6.134, 6.093, 6.025, 6.044]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77, 0.777, 0.804, 0.859, 0.85, 0.886, 0.904, 0.9, 0.895, 0.924, 0.933, 0.94, 0.942]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547, 0.642, 0.589, 0.568, 0.653, 0.632, 0.642, 0.653, 0.663, 0.674, 0.705, 0.695, 0.684]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215, 6.179, 6.134, 6.093, 6.025, 6.044]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :20\n",
      "100% 28/28 [00:08<00:00,  3.24it/s]\n",
      "[Epoch 20] val_acc=0.674 val_auc=0.663 val_loss=6.001\n",
      "Epoch 00021: reducing learning rate of group 0 to 1.5625e-05.\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774, 5.727, 5.68, 5.567, 5.559, 5.467, 5.43, 5.462, 5.434, 5.39, 5.38, 5.36, 5.35, 5.389]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215, 6.179, 6.134, 6.093, 6.025, 6.044, 6.001]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77, 0.777, 0.804, 0.859, 0.85, 0.886, 0.904, 0.9, 0.895, 0.924, 0.933, 0.94, 0.942, 0.917]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547, 0.642, 0.589, 0.568, 0.653, 0.632, 0.642, 0.653, 0.663, 0.674, 0.705, 0.695, 0.684, 0.674]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215, 6.179, 6.134, 6.093, 6.025, 6.044, 6.001]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :21\n",
      "100% 28/28 [00:08<00:00,  3.21it/s]\n",
      "[Epoch 21] val_acc=0.663 val_auc=0.644 val_loss=6.042\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774, 5.727, 5.68, 5.567, 5.559, 5.467, 5.43, 5.462, 5.434, 5.39, 5.38, 5.36, 5.35, 5.389, 5.339]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215, 6.179, 6.134, 6.093, 6.025, 6.044, 6.001, 6.042]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77, 0.777, 0.804, 0.859, 0.85, 0.886, 0.904, 0.9, 0.895, 0.924, 0.933, 0.94, 0.942, 0.917, 0.924]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547, 0.642, 0.589, 0.568, 0.653, 0.632, 0.642, 0.653, 0.663, 0.674, 0.705, 0.695, 0.684, 0.674, 0.663]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215, 6.179, 6.134, 6.093, 6.025, 6.044, 6.001, 6.042]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :22\n",
      "100% 28/28 [00:08<00:00,  3.22it/s]\n",
      "[Epoch 22] val_acc=0.674 val_auc=0.663 val_loss=6.081\n",
      "Early-Stopping at epoch 22 (no val_acc ↑ for 5 epochs)\n",
      "Total training time: 0:04:10\n"
     ]
    }
   ],
   "source": [
    "# baseline\n",
    "!python train.py --dataset Blastocyst \\\n",
    "    --model resnest26d \\\n",
    "    --batch_size 16 \\\n",
    "    --epochs 30 \\\n",
    "    --num_classes 2 \\\n",
    "    --aug true \\\n",
    "    --lr 0.0005 \\\n",
    "    --vis false \\\n",
    "    --weight_decay 0.005 \\\n",
    "    --use_slot false \\\n",
    "    --channel 3 \\\n",
    "    --use_pre true \\\n",
    "    --freeze_layers 3 \\\n",
    "    --dataset_dir /home/work/SCOUTERv2/scouter/data/blastocyst/split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using distributed mode\n",
      "Resume from /home/work/SCOUTERv2/scouter/saved_model/best5.pth → backbone만 로드, 학습은 처음부터 이어서 진행합니다.\n",
      "Start training: epochs=30, batch_size=16, lr=0.0001\n",
      "start train :0\n",
      "100% 28/28 [00:09<00:00,  2.94it/s]\n",
      "[Epoch 0] val_acc=0.589 val_auc=0.720 val_loss=4.223\n",
      "✔ best.pth updated\n",
      "train loss: [0.787]\n",
      "val loss: [4.223]\n",
      "train acc: [0.558]\n",
      "val acc: [0.589]\n",
      "train CE loss [0.551]\n",
      "val CE loss [4.161]\n",
      "train attention loss [0.157]\n",
      "val attention loss [0.042]\n",
      "start train :1\n",
      "100% 28/28 [00:08<00:00,  3.19it/s]\n",
      "[Epoch 1] val_acc=0.589 val_auc=0.616 val_loss=0.948\n",
      "train loss: [0.787, 0.56]\n",
      "val loss: [4.223, 0.948]\n",
      "train acc: [0.558, 0.806]\n",
      "val acc: [0.589, 0.589]\n",
      "train CE loss [0.551, 0.478]\n",
      "val CE loss [4.161, 0.885]\n",
      "train attention loss [0.157, 0.055]\n",
      "val attention loss [0.042, 0.042]\n",
      "start train :2\n",
      "100% 28/28 [00:08<00:00,  3.18it/s]\n",
      "[Epoch 2] val_acc=0.568 val_auc=0.550 val_loss=0.940\n",
      "train loss: [0.787, 0.56, 0.389]\n",
      "val loss: [4.223, 0.948, 0.94]\n",
      "train acc: [0.558, 0.806, 0.859]\n",
      "val acc: [0.589, 0.589, 0.568]\n",
      "train CE loss [0.551, 0.478, 0.34]\n",
      "val CE loss [4.161, 0.885, 0.902]\n",
      "train attention loss [0.157, 0.055, 0.032]\n",
      "val attention loss [0.042, 0.042, 0.025]\n",
      "start train :3\n",
      "100% 28/28 [00:08<00:00,  3.20it/s]\n",
      "[Epoch 3] val_acc=0.589 val_auc=0.685 val_loss=0.686\n",
      "train loss: [0.787, 0.56, 0.389, 0.472]\n",
      "val loss: [4.223, 0.948, 0.94, 0.686]\n",
      "train acc: [0.558, 0.806, 0.859, 0.788]\n",
      "val acc: [0.589, 0.589, 0.568, 0.589]\n",
      "train CE loss [0.551, 0.478, 0.34, 0.438]\n",
      "val CE loss [4.161, 0.885, 0.902, 0.671]\n",
      "train attention loss [0.157, 0.055, 0.032, 0.023]\n",
      "val attention loss [0.042, 0.042, 0.025, 0.01]\n",
      "start train :4\n",
      "100% 28/28 [00:08<00:00,  3.18it/s]\n",
      "[Epoch 4] val_acc=0.663 val_auc=0.667 val_loss=1.177\n",
      "✔ best.pth updated\n",
      "train loss: [0.787, 0.56, 0.389, 0.472, 0.362]\n",
      "val loss: [4.223, 0.948, 0.94, 0.686, 1.177]\n",
      "train acc: [0.558, 0.806, 0.859, 0.788, 0.853]\n",
      "val acc: [0.589, 0.589, 0.568, 0.589, 0.663]\n",
      "train CE loss [0.551, 0.478, 0.34, 0.438, 0.343]\n",
      "val CE loss [4.161, 0.885, 0.902, 0.671, 1.167]\n",
      "train attention loss [0.157, 0.055, 0.032, 0.023, 0.013]\n",
      "val attention loss [0.042, 0.042, 0.025, 0.01, 0.007]\n",
      "start train :5\n",
      "100% 28/28 [00:08<00:00,  3.21it/s]\n",
      "[Epoch 5] val_acc=0.600 val_auc=0.621 val_loss=0.706\n",
      "train loss: [0.787, 0.56, 0.389, 0.472, 0.362, 0.402]\n",
      "val loss: [4.223, 0.948, 0.94, 0.686, 1.177, 0.706]\n",
      "train acc: [0.558, 0.806, 0.859, 0.788, 0.853, 0.81]\n",
      "val acc: [0.589, 0.589, 0.568, 0.589, 0.663, 0.6]\n",
      "train CE loss [0.551, 0.478, 0.34, 0.438, 0.343, 0.388]\n",
      "val CE loss [4.161, 0.885, 0.902, 0.671, 1.167, 0.696]\n",
      "train attention loss [0.157, 0.055, 0.032, 0.023, 0.013, 0.009]\n",
      "val attention loss [0.042, 0.042, 0.025, 0.01, 0.007, 0.007]\n",
      "start train :6\n",
      "100% 28/28 [00:08<00:00,  3.20it/s]\n",
      "[Epoch 6] val_acc=0.611 val_auc=0.661 val_loss=1.688\n",
      "train loss: [0.787, 0.56, 0.389, 0.472, 0.362, 0.402, 0.293]\n",
      "val loss: [4.223, 0.948, 0.94, 0.686, 1.177, 0.706, 1.688]\n",
      "train acc: [0.558, 0.806, 0.859, 0.788, 0.853, 0.81, 0.893]\n",
      "val acc: [0.589, 0.589, 0.568, 0.589, 0.663, 0.6, 0.611]\n",
      "train CE loss [0.551, 0.478, 0.34, 0.438, 0.343, 0.388, 0.282]\n",
      "val CE loss [4.161, 0.885, 0.902, 0.671, 1.167, 0.696, 1.683]\n",
      "train attention loss [0.157, 0.055, 0.032, 0.023, 0.013, 0.009, 0.007]\n",
      "val attention loss [0.042, 0.042, 0.025, 0.01, 0.007, 0.007, 0.004]\n",
      "start train :7\n",
      "100% 28/28 [00:08<00:00,  3.19it/s]\n",
      "[Epoch 7] val_acc=0.547 val_auc=0.644 val_loss=1.057\n",
      "Epoch 00008: reducing learning rate of group 0 to 5.0000e-05.\n",
      "train loss: [0.787, 0.56, 0.389, 0.472, 0.362, 0.402, 0.293, 0.223]\n",
      "val loss: [4.223, 0.948, 0.94, 0.686, 1.177, 0.706, 1.688, 1.057]\n",
      "train acc: [0.558, 0.806, 0.859, 0.788, 0.853, 0.81, 0.893, 0.906]\n",
      "val acc: [0.589, 0.589, 0.568, 0.589, 0.663, 0.6, 0.611, 0.547]\n",
      "train CE loss [0.551, 0.478, 0.34, 0.438, 0.343, 0.388, 0.282, 0.215]\n",
      "val CE loss [4.161, 0.885, 0.902, 0.671, 1.167, 0.696, 1.683, 1.049]\n",
      "train attention loss [0.157, 0.055, 0.032, 0.023, 0.013, 0.009, 0.007, 0.005]\n",
      "val attention loss [0.042, 0.042, 0.025, 0.01, 0.007, 0.007, 0.004, 0.005]\n",
      "start train :8\n",
      "100% 28/28 [00:08<00:00,  3.20it/s]\n",
      "[Epoch 8] val_acc=0.611 val_auc=0.620 val_loss=1.014\n",
      "train loss: [0.787, 0.56, 0.389, 0.472, 0.362, 0.402, 0.293, 0.223, 0.189]\n",
      "val loss: [4.223, 0.948, 0.94, 0.686, 1.177, 0.706, 1.688, 1.057, 1.014]\n",
      "train acc: [0.558, 0.806, 0.859, 0.788, 0.853, 0.81, 0.893, 0.906, 0.917]\n",
      "val acc: [0.589, 0.589, 0.568, 0.589, 0.663, 0.6, 0.611, 0.547, 0.611]\n",
      "train CE loss [0.551, 0.478, 0.34, 0.438, 0.343, 0.388, 0.282, 0.215, 0.183]\n",
      "val CE loss [4.161, 0.885, 0.902, 0.671, 1.167, 0.696, 1.683, 1.049, 1.009]\n",
      "train attention loss [0.157, 0.055, 0.032, 0.023, 0.013, 0.009, 0.007, 0.005, 0.004]\n",
      "val attention loss [0.042, 0.042, 0.025, 0.01, 0.007, 0.007, 0.004, 0.005, 0.003]\n",
      "start train :9\n",
      "100% 28/28 [00:08<00:00,  3.19it/s]\n",
      "[Epoch 9] val_acc=0.663 val_auc=0.632 val_loss=1.217\n",
      "Early-Stopping at epoch 9 (no val_acc ↑ for 5 epochs)\n",
      "Total training time: 0:01:46\n"
     ]
    }
   ],
   "source": [
    "# slot-positive\n",
    "!python train_slot.py \\\n",
    "  --dataset Blastocyst \\\n",
    "  --model resnest26d \\\n",
    "  --batch_size 16 \\\n",
    "  --epochs 30 \\\n",
    "  --num_classes 2 \\\n",
    "  --use_slot true \\\n",
    "  --use_pre false \\\n",
    "  --loss_status 1 \\\n",
    "  --slots_per_class 3 \\\n",
    "  --power 2 \\\n",
    "  --to_k_layer 1 \\\n",
    "  --lambda_value 1.5 \\\n",
    "  --vis false \\\n",
    "  --freeze_layers 1 \\\n",
    "  --resume /home/work/SCOUTERv2/scouter/saved_model/best5.pth \\\n",
    "  --dataset_dir /home/work/SCOUTERv2/scouter/data/blastocyst/split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using distributed mode\n",
      "Resume from /home/work/SCOUTERv2/scouter/saved_model/best5.pth → backbone만 로드, 학습은 처음부터 이어서 진행합니다.\n",
      "Start training: epochs=30, batch_size=16, lr=0.0001\n",
      "start train :0\n",
      "100% 28/28 [00:09<00:00,  2.88it/s]\n",
      "[Epoch 0] val_acc=0.674 val_auc=0.570 val_loss=1.655\n",
      "✔ best.pth updated\n",
      "train loss: [1.132]\n",
      "val loss: [1.655]\n",
      "train acc: [0.754]\n",
      "val acc: [0.674]\n",
      "train CE loss [0.583]\n",
      "val CE loss [1.286]\n",
      "train attention loss [0.183]\n",
      "val attention loss [0.123]\n",
      "start train :1\n",
      "100% 28/28 [00:08<00:00,  3.18it/s]\n",
      "[Epoch 1] val_acc=0.568 val_auc=0.584 val_loss=1.921\n",
      "train loss: [1.132, 0.686]\n",
      "val loss: [1.655, 1.921]\n",
      "train acc: [0.754, 0.842]\n",
      "val acc: [0.674, 0.568]\n",
      "train CE loss [0.583, 0.377]\n",
      "val CE loss [1.286, 1.726]\n",
      "train attention loss [0.183, 0.103]\n",
      "val attention loss [0.123, 0.065]\n",
      "start train :2\n",
      "100% 28/28 [00:08<00:00,  3.20it/s]\n",
      "[Epoch 2] val_acc=0.621 val_auc=0.647 val_loss=1.124\n",
      "train loss: [1.132, 0.686, 0.46]\n",
      "val loss: [1.655, 1.921, 1.124]\n",
      "train acc: [0.754, 0.842, 0.882]\n",
      "val acc: [0.674, 0.568, 0.621]\n",
      "train CE loss [0.583, 0.377, 0.325]\n",
      "val CE loss [1.286, 1.726, 1.048]\n",
      "train attention loss [0.183, 0.103, 0.045]\n",
      "val attention loss [0.123, 0.065, 0.026]\n",
      "start train :3\n",
      "100% 28/28 [00:08<00:00,  3.20it/s]\n",
      "[Epoch 3] val_acc=0.705 val_auc=0.698 val_loss=1.650\n",
      "✔ best.pth updated\n",
      "train loss: [1.132, 0.686, 0.46, 0.302]\n",
      "val loss: [1.655, 1.921, 1.124, 1.65]\n",
      "train acc: [0.754, 0.842, 0.882, 0.904]\n",
      "val acc: [0.674, 0.568, 0.621, 0.705]\n",
      "train CE loss [0.583, 0.377, 0.325, 0.252]\n",
      "val CE loss [1.286, 1.726, 1.048, 1.624]\n",
      "train attention loss [0.183, 0.103, 0.045, 0.017]\n",
      "val attention loss [0.123, 0.065, 0.026, 0.009]\n",
      "start train :4\n",
      "100% 28/28 [00:08<00:00,  3.19it/s]\n",
      "[Epoch 4] val_acc=0.653 val_auc=0.627 val_loss=1.075\n",
      "train loss: [1.132, 0.686, 0.46, 0.302, 0.287]\n",
      "val loss: [1.655, 1.921, 1.124, 1.65, 1.075]\n",
      "train acc: [0.754, 0.842, 0.882, 0.904, 0.908]\n",
      "val acc: [0.674, 0.568, 0.621, 0.705, 0.653]\n",
      "train CE loss [0.583, 0.377, 0.325, 0.252, 0.267]\n",
      "val CE loss [1.286, 1.726, 1.048, 1.624, 1.069]\n",
      "train attention loss [0.183, 0.103, 0.045, 0.017, 0.007]\n",
      "val attention loss [0.123, 0.065, 0.026, 0.009, 0.002]\n",
      "start train :5\n",
      "100% 28/28 [00:08<00:00,  3.19it/s]\n",
      "[Epoch 5] val_acc=0.674 val_auc=0.623 val_loss=1.225\n",
      "train loss: [1.132, 0.686, 0.46, 0.302, 0.287, 0.222]\n",
      "val loss: [1.655, 1.921, 1.124, 1.65, 1.075, 1.225]\n",
      "train acc: [0.754, 0.842, 0.882, 0.904, 0.908, 0.922]\n",
      "val acc: [0.674, 0.568, 0.621, 0.705, 0.653, 0.674]\n",
      "train CE loss [0.583, 0.377, 0.325, 0.252, 0.267, 0.212]\n",
      "val CE loss [1.286, 1.726, 1.048, 1.624, 1.069, 1.21]\n",
      "train attention loss [0.183, 0.103, 0.045, 0.017, 0.007, 0.004]\n",
      "val attention loss [0.123, 0.065, 0.026, 0.009, 0.002, 0.005]\n",
      "start train :6\n",
      "100% 28/28 [00:08<00:00,  3.18it/s]\n",
      "[Epoch 6] val_acc=0.589 val_auc=0.653 val_loss=2.121\n",
      "train loss: [1.132, 0.686, 0.46, 0.302, 0.287, 0.222, 0.152]\n",
      "val loss: [1.655, 1.921, 1.124, 1.65, 1.075, 1.225, 2.121]\n",
      "train acc: [0.754, 0.842, 0.882, 0.904, 0.908, 0.922, 0.94]\n",
      "val acc: [0.674, 0.568, 0.621, 0.705, 0.653, 0.674, 0.589]\n",
      "train CE loss [0.583, 0.377, 0.325, 0.252, 0.267, 0.212, 0.144]\n",
      "val CE loss [1.286, 1.726, 1.048, 1.624, 1.069, 1.21, 2.112]\n",
      "train attention loss [0.183, 0.103, 0.045, 0.017, 0.007, 0.004, 0.003]\n",
      "val attention loss [0.123, 0.065, 0.026, 0.009, 0.002, 0.005, 0.003]\n",
      "start train :7\n",
      "100% 28/28 [00:08<00:00,  3.17it/s]\n",
      "[Epoch 7] val_acc=0.558 val_auc=0.549 val_loss=1.079\n",
      "train loss: [1.132, 0.686, 0.46, 0.302, 0.287, 0.222, 0.152, 0.241]\n",
      "val loss: [1.655, 1.921, 1.124, 1.65, 1.075, 1.225, 2.121, 1.079]\n",
      "train acc: [0.754, 0.842, 0.882, 0.904, 0.908, 0.922, 0.94, 0.926]\n",
      "val acc: [0.674, 0.568, 0.621, 0.705, 0.653, 0.674, 0.589, 0.558]\n",
      "train CE loss [0.583, 0.377, 0.325, 0.252, 0.267, 0.212, 0.144, 0.237]\n",
      "val CE loss [1.286, 1.726, 1.048, 1.624, 1.069, 1.21, 2.112, 1.074]\n",
      "train attention loss [0.183, 0.103, 0.045, 0.017, 0.007, 0.004, 0.003, 0.001]\n",
      "val attention loss [0.123, 0.065, 0.026, 0.009, 0.002, 0.005, 0.003, 0.002]\n",
      "start train :8\n",
      "100% 28/28 [00:08<00:00,  3.16it/s]\n",
      "[Epoch 8] val_acc=0.621 val_auc=0.576 val_loss=1.288\n",
      "Epoch 00009: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Early-Stopping at epoch 8 (no val_acc ↑ for 5 epochs)\n",
      "Total training time: 0:01:37\n"
     ]
    }
   ],
   "source": [
    "# slot-negative\n",
    "!python train_slot.py \\\n",
    "  --dataset Blastocyst \\\n",
    "  --model resnest26d \\\n",
    "  --batch_size 16 \\\n",
    "  --epochs 30 \\\n",
    "  --num_classes 2 \\\n",
    "  --use_slot true \\\n",
    "  --use_pre false \\\n",
    "  --loss_status -1 \\\n",
    "  --slots_per_class 1 \\\n",
    "  --power 2 \\\n",
    "  --to_k_layer 3 \\\n",
    "  --lambda_value 3.0 \\\n",
    "  --lr 0.0001 \\\n",
    "  --vis false \\\n",
    "  --freeze_layers 1 \\\n",
    "  --resume /home/work/SCOUTERv2/scouter/saved_model/best5.pth \\\n",
    "  --dataset_dir /home/work/SCOUTERv2/scouter/data/blastocyst/split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground-truth label:\t 1\n",
      "Checkpoint keys: ['model', 'optimizer', 'lr_scheduler', 'epoch', 'args', 'best_acc']\n",
      "Raw logits: [-2.0683885  -0.13512045]\n",
      "Predicted class: 1\n"
     ]
    }
   ],
   "source": [
    "!python test.py \\\n",
    "  --dataset Blastocyst \\\n",
    "  --model resnest26d \\\n",
    "  --batch_size 16 \\\n",
    "  --num_classes 2 \\\n",
    "  --use_slot true \\\n",
    "  --use_pre false \\\n",
    "  --loss_status 1 \\\n",
    "  --slots_per_class 1 \\\n",
    "  --power 2 \\\n",
    "  --to_k_layer 1 \\\n",
    "  --lambda_value 1.5 \\\n",
    "  --vis true \\\n",
    "  --freeze_layers 1 \\\n",
    "  --dataset_dir /home/work/SCOUTERv2/scouter/data/blastocyst/split \\\n",
    "  --output_dir saved_model/best3p-slot.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground-truth label:\t 1\n",
      "Checkpoint keys: ['model', 'optimizer', 'lr_scheduler', 'epoch', 'args', 'best_acc']\n",
      "Raw logits: [-2.258872  -0.1103376]\n",
      "Predicted class: 1\n"
     ]
    }
   ],
   "source": [
    "!python test.py \\\n",
    "  --dataset Blastocyst \\\n",
    "  --model resnest26d \\\n",
    "  --batch_size 16 \\\n",
    "  --num_classes 2 \\\n",
    "  --use_slot true \\\n",
    "  --use_pre false \\\n",
    "  --loss_status -1 \\\n",
    "  --slots_per_class 1 \\\n",
    "  --power 2 \\\n",
    "  --to_k_layer 3 \\\n",
    "  --lambda_value 3.0 \\\n",
    "  --vis true \\\n",
    "  --freeze_layers 1 \\\n",
    "  --dataset_dir /home/work/SCOUTERv2/scouter/data/blastocyst/split \\\n",
    "  --output_dir saved_model/best5n-slot.pth"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] generating explanation images …\n",
      "Predicting labels: 100% 1/1 [00:00<00:00,  6.02it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 176.45it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 59.65it/s]\n",
      "AUC: 0.6042893525947315\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 70.17it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 877.65it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 58.05it/s]\n",
      "AUC: 0.5481977279647253\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 54.71it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 339.45it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 58.84it/s]\n",
      "AUC: 0.48264796394639864\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 70.33it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 1583.35it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 59.57it/s]\n",
      "AUC: 0.481679073191033\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 52.94it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 136.61it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 59.52it/s]\n",
      "AUC: 0.35365271028399897\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 67.02it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 1705.69it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 58.25it/s]\n",
      "AUC: 0.30144717099342067\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 69.81it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 337.62it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 60.21it/s]\n",
      "AUC: 0.5089603895442382\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 68.81it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 1904.77it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 60.01it/s]\n",
      "AUC: 0.4748181057180493\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 70.24it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 347.30it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 59.28it/s]\n",
      "AUC: 0.6653149597776624\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 70.85it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 1927.53it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 57.84it/s]\n",
      "AUC: 0.5313928491776236\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 69.43it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 340.56it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 59.64it/s]\n",
      "AUC: 0.48044305596984205\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 69.91it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 1974.72it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 60.55it/s]\n",
      "AUC: 0.40105671115721075\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 69.52it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 346.69it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 60.04it/s]\n",
      "AUC: 0.5040083442743007\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 70.35it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 1106.97it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 60.65it/s]\n",
      "AUC: 0.4913187443744391\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 69.39it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 338.30it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 58.77it/s]\n",
      "AUC: 0.7029803176482137\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 67.23it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 1880.85it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 58.28it/s]\n",
      "AUC: 0.574927658055206\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 69.18it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 345.81it/s]\n",
      "Inserting pixels: 100% 261/261 [00:05<00:00, 49.79it/s]\n",
      "AUC: 0.6600846969710591\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 32.21it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 1788.62it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 58.76it/s]\n",
      "AUC: 0.6263639361167757\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 39.60it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 342.59it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 60.46it/s]\n",
      "AUC: 0.47641461569583043\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 71.31it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 2107.69it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 59.54it/s]\n",
      "AUC: 0.5582563972069273\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 72.59it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 347.27it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 61.05it/s]\n",
      "AUC: 0.6112432625449191\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 68.74it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 2076.39it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 61.76it/s]\n",
      "AUC: 0.5790434631339919\n",
      "Predicting labels: 100% 1/1 [00:00<00:00,  7.55it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 210.69it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 62.75it/s]\n",
      "AUC: 0.7067889040602104\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 69.06it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 282.60it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 54.24it/s]\n",
      "AUC: 0.6252566730726387\n",
      "IAUC=0.5631 | DAUC=0.5161\n",
      "Infidelity=0.0085 | Sensitivity=1.4316\n",
      "Infidelity per pert: {'Gaussian': 0.008507067155110563}\n",
      "Sensitivity per pert: {'Gaussian': 1.431602638312834}\n"
     ]
    }
   ],
   "source": [
    "!python eval_blasto.py \\\n",
    "  --dataset_dir /home/work/SCOUTERv2/scouter/data/blastocyst/split \\\n",
    "  --checkpoint  /home/work/SCOUTERv2/scouter/saved_model/best3p-slot.pth \\\n",
    "  --model resnest26d \\\n",
    "  --use_slot true \\\n",
    "  --loss_status 1 \\\n",
    "  --to_k_layer 1 \\\n",
    "  --lambda_value 1.5 \\\n",
    "  --freeze_layers 1 \\\n",
    "  --vis true \\\n",
    "  --auc --saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] generating explanation images …\n",
      "Predicting labels: 100% 1/1 [00:00<00:00,  5.88it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 122.19it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 58.06it/s]\n",
      "AUC: 0.7431441300271008\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 65.81it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 850.08it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 58.29it/s]\n",
      "AUC: 0.6124524598938059\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 67.95it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 341.11it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 57.54it/s]\n",
      "AUC: 0.7108251866168127\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 66.30it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 1825.99it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 58.08it/s]\n",
      "AUC: 0.609533343782935\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 67.37it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 345.89it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 52.71it/s]\n",
      "AUC: 0.6362009194321357\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 68.00it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 1785.57it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 57.78it/s]\n",
      "AUC: 0.5448715538108865\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 64.58it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 339.43it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 59.01it/s]\n",
      "AUC: 0.8016099772792167\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 69.20it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 1235.44it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 58.76it/s]\n",
      "AUC: 0.6722781900971803\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 67.82it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 334.07it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 58.04it/s]\n",
      "AUC: 0.8076771907759114\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 68.17it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 1948.12it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 58.00it/s]\n",
      "AUC: 0.7728852772082274\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 35.25it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 334.61it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 57.80it/s]\n",
      "AUC: 0.6688346989315715\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 65.77it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 1507.66it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:06<00:00, 42.65it/s]\n",
      "AUC: 0.6500682613037567\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 52.44it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 343.18it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 58.47it/s]\n",
      "AUC: 0.6878495784668652\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 68.40it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 1994.44it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 58.08it/s]\n",
      "AUC: 0.6386256792538225\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 53.53it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 340.75it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 57.95it/s]\n",
      "AUC: 0.5241606872589237\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 65.51it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 1953.56it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 58.54it/s]\n",
      "AUC: 0.6252983517364975\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 67.45it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 341.64it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 56.96it/s]\n",
      "AUC: 0.6787870273979094\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 66.00it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 1745.44it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 56.46it/s]\n",
      "AUC: 0.6238652992205551\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 66.69it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 333.07it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 53.90it/s]\n",
      "AUC: 0.6332245191854502\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 49.66it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 2011.66it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 57.74it/s]\n",
      "AUC: 0.5960463498403372\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 70.19it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 351.28it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 58.17it/s]\n",
      "AUC: 0.6627980736260296\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 47.76it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 1909.11it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 58.34it/s]\n",
      "AUC: 0.4900058269634358\n",
      "Predicting labels: 100% 1/1 [00:00<00:00,  7.50it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 209.33it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 58.57it/s]\n",
      "AUC: 0.6625330613798124\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 67.36it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 2155.35it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 57.78it/s]\n",
      "AUC: 0.7298874960972093\n",
      "IAUC=0.6848 | DAUC=0.6305\n",
      "Infidelity=0.0111 | Sensitivity=2.2626\n",
      "Infidelity per pert: {'Gaussian': 0.011053571601433358}\n",
      "Sensitivity per pert: {'Gaussian': 2.2626394132219176}\n"
     ]
    }
   ],
   "source": [
    "!python eval_blasto.py \\\n",
    "  --dataset_dir /home/work/SCOUTERv2/scouter/data/blastocyst/split \\\n",
    "  --checkpoint  /home/work/SCOUTERv2/scouter/saved_model/best5n-slot.pth \\\n",
    "  --model resnest26d \\\n",
    "  --use_slot true \\\n",
    "  --loss_status -1 \\\n",
    "  --to_k_layer 3 \\\n",
    "  --lambda_value 3.0 \\\n",
    "  --freeze_layers 1 \\\n",
    "  --vis true \\\n",
    "  --auc --saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from /home/work/SCOUTERv2/scouter/saved_model/best3p-slot.pth\n",
      "{'auc': 0.6852678571428571, 'accuracy': 0.796875, 'precision': 0.3333333333333333, 'recall': 0.625, 'f1': 0.43478260869565216, 'kappa': 0.3246753246753247}\n"
     ]
    }
   ],
   "source": [
    "!python confusion_matrix_metrics.py \\\n",
    "  --dataset Blastocyst \\\n",
    "  --checkpoint /home/work/SCOUTERv2/scouter/saved_model/best3p-slot.pth \\\n",
    "  --dataset_dir /home/work/SCOUTERv2/scouter/data/blastocyst/split \\\n",
    "  --model resnest26d \\\n",
    "  --use_slot true \\\n",
    "  --loss_status 1 \\\n",
    "  --to_k_layer 1 \\\n",
    "  --lambda_value 1.5 \\\n",
    "  --slots_per_class 1 \\\n",
    "  --power 2 \\\n",
    "  --freeze_layers 1 \\\n",
    "  --output_dir saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from /home/work/SCOUTERv2/scouter/saved_model/best5n-slot.pth\n",
      "{'auc': 0.7142857142857143, 'accuracy': 0.796875, 'precision': 0.2727272727272727, 'recall': 0.375, 'f1': 0.3157894736842105, 'kappa': 0.19999999999999996}\n"
     ]
    }
   ],
   "source": [
    "!python confusion_matrix_metrics.py \\\n",
    "  --dataset Blastocyst \\\n",
    "  --checkpoint /home/work/SCOUTERv2/scouter/saved_model/best5n-slot.pth \\\n",
    "  --dataset_dir /home/work/SCOUTERv2/scouter/data/blastocyst/split \\\n",
    "  --model resnest26d \\\n",
    "  --use_slot true \\\n",
    "  --loss_status -1 \\\n",
    "  --to_k_layer 3 \\\n",
    "  --lambda_value 3.0 \\\n",
    "  --slots_per_class 1 \\\n",
    "  --power 2 \\\n",
    "  --freeze_layers 1 \\\n",
    "  --output_dir saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from /home/work/SCOUTERv2/scouter/saved_model/best5.pth\n",
      "{'auc': 0.7522321428571428, 'accuracy': 0.828125, 'precision': 0.36363636363636365, 'recall': 0.5, 'f1': 0.4210526315789474, 'kappa': 0.32307692307692304}\n"
     ]
    }
   ],
   "source": [
    "# baseline\n",
    "!python confusion_matrix_metrics.py \\\n",
    "  --dataset Blastocyst \\\n",
    "  --checkpoint /home/work/SCOUTERv2/scouter/saved_model/best5.pth \\\n",
    "  --dataset_dir /home/work/SCOUTERv2/scouter/data/blastocyst/split \\\n",
    "  --model resnest26d \\\n",
    "  --freeze_layers 3 \\\n",
    "  --channel 3 \\\n",
    "  --use_slot false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%run view_cm.py \\\n",
    "  --dataset Blastocyst \\\n",
    "  --dataset_dir /home/work/SCOUTERv2/scouter/data/blastocyst/split \\\n",
    "  --checkpoint /home/work/SCOUTERv2/scouter/saved_model/best5.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%run view_cm.py \\\n",
    "  --dataset Blastocyst \\\n",
    "  --dataset_dir /home/work/SCOUTERv2/scouter/data/blastocyst/split \\\n",
    "  --checkpoint /home/work/SCOUTERv2/scouter/saved_model/best3p-slot.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%run view_cm.py \\\n",
    "  --dataset Blastocyst \\\n",
    "  --dataset_dir /home/work/SCOUTERv2/scouter/data/blastocyst/split \\\n",
    "  --checkpoint /home/work/SCOUTERv2/scouter/saved_model/best5n-slot.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
