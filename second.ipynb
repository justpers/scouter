{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/home/work/SCOUTERv2/scouter'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting certifi==2020.6.20 (from -r requirements.txt (line 1))\n",
      "  Using cached certifi-2020.6.20-py2.py3-none-any.whl (156 kB)\n",
      "Collecting cycler==0.10.0 (from -r requirements.txt (line 2))\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.4.2)\n",
      "Collecting future==0.18.2 (from -r requirements.txt (line 4))\n",
      "  Using cached future-0.18.2-py3-none-any.whl\n",
      "Collecting imageio==2.9.0 (from -r requirements.txt (line 5))\n",
      "  Using cached imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "Requirement already satisfied: imgaug==0.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.4.0)\n",
      "Collecting joblib==0.16.0 (from -r requirements.txt (line 7))\n",
      "  Using cached joblib-0.16.0-py3-none-any.whl (300 kB)\n",
      "Collecting kiwisolver==1.2.0 (from -r requirements.txt (line 8))\n",
      "  Using cached kiwisolver-1.2.0-cp310-cp310-linux_x86_64.whl\n",
      "Collecting matplotlib==3.3.1 (from -r requirements.txt (line 9))\n",
      "  Using cached matplotlib-3.3.1-cp310-cp310-linux_x86_64.whl\n",
      "Collecting networkx==2.5 (from -r requirements.txt (line 10))\n",
      "  Using cached networkx-2.5-py3-none-any.whl (1.6 MB)\n",
      "Collecting nose==1.3.7 (from -r requirements.txt (line 11))\n",
      "  Using cached nose-1.3.7-py3-none-any.whl (154 kB)\n",
      "Collecting numpy==1.21.6 (from -r requirements.txt (line 13))\n",
      "  Using cached numpy-1.21.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
      "Collecting opencv-python==4.5.5.64 (from -r requirements.txt (line 15))\n",
      "  Using cached opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
      "Collecting Pillow==7.2.0 (from -r requirements.txt (line 16))\n",
      "  Using cached Pillow-7.2.0-cp310-cp310-linux_x86_64.whl\n",
      "Collecting prefetch-generator==1.0.1 (from -r requirements.txt (line 17))\n",
      "  Using cached prefetch_generator-1.0.1-py3-none-any.whl\n",
      "Collecting pyparsing==2.4.7 (from -r requirements.txt (line 18))\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Collecting python-dateutil==2.8.1 (from -r requirements.txt (line 19))\n",
      "  Using cached python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting PyWavelets==1.4.1 (from -r requirements.txt (line 21))\n",
      "  Using cached PyWavelets-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n",
      "Collecting scikit-image==0.18.3 (from -r requirements.txt (line 23))\n",
      "  Using cached scikit-image-0.18.3.tar.gz (29.2 MB)\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting scikit-learn==1.0.2 (from -r requirements.txt (line 25))\n",
      "  Using cached scikit_learn-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
      "Collecting scipy==1.7.3 (from -r requirements.txt (line 27))\n",
      "  Using cached scipy-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.9 MB)\n",
      "Collecting Shapely==1.8.0 (from -r requirements.txt (line 29))\n",
      "  Using cached Shapely-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Collecting six==1.15.0 (from -r requirements.txt (line 30))\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting tensorly==0.6.0 (from -r requirements.txt (line 32))\n",
      "  Using cached tensorly-0.6.0-py3-none-any.whl (160 kB)\n",
      "Collecting thop==0.1.1.post2209072238 (from -r requirements.txt (line 33))\n",
      "  Using cached thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Collecting threadpoolctl==2.1.0 (from -r requirements.txt (line 35))\n",
      "  Using cached threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting tifffile==2020.9.3 (from -r requirements.txt (line 36))\n",
      "  Using cached tifffile-2020.9.3-py3-none-any.whl (148 kB)\n",
      "Collecting torch==1.11.0 (from -r requirements.txt (line 38))\n",
      "  Using cached torch-1.11.0-cp310-cp310-manylinux1_x86_64.whl (750.6 MB)\n",
      "Collecting torchvision==0.12.0 (from -r requirements.txt (line 40))\n",
      "  Using cached torchvision-0.12.0-cp310-cp310-manylinux1_x86_64.whl (21.0 MB)\n",
      "Collecting tqdm==4.49.0 (from -r requirements.txt (line 41))\n",
      "  Using cached tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.11.0->-r requirements.txt (line 38)) (4.9.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0->-r requirements.txt (line 40)) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0->-r requirements.txt (line 40)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0->-r requirements.txt (line 40)) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0->-r requirements.txt (line 40)) (2.0.7)\n",
      "Building wheels for collected packages: scikit-image\n",
      "  Building wheel for scikit-image (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for scikit-image: filename=scikit_image-0.18.3-cp310-cp310-linux_x86_64.whl size=35357926 sha256=a4580c68294ff75751ebf1e0ddeac5f9d372695527671bb5d0f2cc5676abb01e\n",
      "  Stored in directory: /home/work/.cache/pip/wheels/9d/55/80/c5bf730bc10906b1518cd6ebc05c87e69d1c46099ebdc9f59f\n",
      "Successfully built scikit-image\n",
      "Installing collected packages: prefetch-generator, nose, certifi, tqdm, torch, threadpoolctl, six, Shapely, pyparsing, Pillow, numpy, networkx, kiwisolver, joblib, future, torchvision, tifffile, thop, scipy, PyWavelets, python-dateutil, opencv-python, imageio, cycler, tensorly, scikit-learn, matplotlib, scikit-image\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lida 0.0.10 requires fastapi, which is not installed.\n",
      "lida 0.0.10 requires kaleido, which is not installed.\n",
      "lida 0.0.10 requires python-multipart, which is not installed.\n",
      "lida 0.0.10 requires uvicorn, which is not installed.\n",
      "llmx 0.0.15a0 requires cohere, which is not installed.\n",
      "llmx 0.0.15a0 requires openai, which is not installed.\n",
      "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
      "arviz 0.15.1 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
      "bigframes 0.16.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.0.2 which is incompatible.\n",
      "fastai 2.7.13 requires pillow>=9.0.0, but you have pillow 7.2.0 which is incompatible.\n",
      "flax 0.7.5 requires numpy>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
      "google-colab 1.0.0 requires notebook==6.5.5, but you have notebook 7.1.2 which is incompatible.\n",
      "ibis-framework 6.2.0 requires python-dateutil<3,>=2.8.2, but you have python-dateutil 2.8.1 which is incompatible.\n",
      "imbalanced-learn 0.10.1 requires joblib>=1.1.1, but you have joblib 0.16.0 which is incompatible.\n",
      "jax 0.4.20 requires numpy>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
      "jax 0.4.20 requires scipy>=1.9, but you have scipy 1.7.3 which is incompatible.\n",
      "jaxlib 0.4.20+cuda12.cudnn89 requires numpy>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
      "jaxlib 0.4.20+cuda12.cudnn89 requires scipy>=1.9, but you have scipy 1.7.3 which is incompatible.\n",
      "jupyter-client 8.6.1 requires python-dateutil>=2.8.2, but you have python-dateutil 2.8.1 which is incompatible.\n",
      "mizani 0.9.3 requires matplotlib>=3.5.0, but you have matplotlib 3.3.1 which is incompatible.\n",
      "numba 0.58.1 requires numpy<1.27,>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
      "plotnine 0.12.4 requires matplotlib>=3.6.0, but you have matplotlib 3.3.1 which is incompatible.\n",
      "plotnine 0.12.4 requires numpy>=1.23.0, but you have numpy 1.21.6 which is incompatible.\n",
      "tensorflow 2.15.0 requires numpy<2.0.0,>=1.23.5, but you have numpy 1.21.6 which is incompatible.\n",
      "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\n",
      "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 1.11.0 which is incompatible.\n",
      "torchdata 0.7.0 requires torch==2.1.0, but you have torch 1.11.0 which is incompatible.\n",
      "torchtext 0.16.0 requires torch==2.1.0, but you have torch 1.11.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Pillow-7.2.0 PyWavelets-1.4.1 Shapely-1.8.0 certifi-2020.6.20 cycler-0.10.0 future-0.18.2 imageio-2.9.0 joblib-0.16.0 kiwisolver-1.2.0 matplotlib-3.3.1 networkx-2.5 nose-1.3.7 numpy-1.21.6 opencv-python-4.5.5.64 prefetch-generator-1.0.1 pyparsing-2.4.7 python-dateutil-2.8.1 scikit-image-0.18.3 scikit-learn-1.0.2 scipy-1.7.3 six-1.15.0 tensorly-0.6.0 thop-0.1.1.post2209072238 threadpoolctl-2.1.0 tifffile-2020.9.3 torch-1.11.0 torchvision-0.12.0 tqdm-4.49.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "PIL",
         "certifi",
         "cycler",
         "dateutil",
         "kiwisolver",
         "matplotlib",
         "mpl_toolkits",
         "numpy",
         "pyparsing",
         "six"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-image==0.18.3 in /home/work/.local/lib/python3.10/site-packages (0.18.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /home/work/.local/lib/python3.10/site-packages (from scikit-image==0.18.3) (1.21.6)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /home/work/.local/lib/python3.10/site-packages (from scikit-image==0.18.3) (1.7.3)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /home/work/.local/lib/python3.10/site-packages (from scikit-image==0.18.3) (3.3.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /home/work/.local/lib/python3.10/site-packages (from scikit-image==0.18.3) (2.5)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /home/work/.local/lib/python3.10/site-packages (from scikit-image==0.18.3) (7.2.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /home/work/.local/lib/python3.10/site-packages (from scikit-image==0.18.3) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/work/.local/lib/python3.10/site-packages (from scikit-image==0.18.3) (2020.9.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/work/.local/lib/python3.10/site-packages (from scikit-image==0.18.3) (1.4.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /home/work/.local/lib/python3.10/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.3) (2020.6.20)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/work/.local/lib/python3.10/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.3) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/work/.local/lib/python3.10/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.3) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/work/.local/lib/python3.10/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.3) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/work/.local/lib/python3.10/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.3) (2.8.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from networkx>=2.0->scikit-image==0.18.3) (4.4.2)\n",
      "Requirement already satisfied: six in /home/work/.local/lib/python3.10/site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.3) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scikit-image==0.18.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.21.6\n",
      "Uninstalling numpy-1.21.6:\n",
      "  Successfully uninstalled numpy-1.21.6\n",
      "Found existing installation: matplotlib 3.3.1\n",
      "Uninstalling matplotlib-3.3.1:\n",
      "  Successfully uninstalled matplotlib-3.3.1\n",
      "Found existing installation: scipy 1.7.3\n",
      "Uninstalling scipy-1.7.3:\n",
      "  Successfully uninstalled scipy-1.7.3\n",
      "Found existing installation: scikit-image 0.18.3\n",
      "Uninstalling scikit-image-0.18.3:\n",
      "  Successfully uninstalled scikit-image-0.18.3\n",
      "Found existing installation: PyWavelets 1.4.1\n",
      "Uninstalling PyWavelets-1.4.1:\n",
      "  Successfully uninstalled PyWavelets-1.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y numpy matplotlib scipy scikit-image PyWavelets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
      "Collecting matplotlib==3.6.3\n",
      "  Downloading matplotlib-3.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting scipy==1.9.3\n",
      "  Downloading scipy-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.7/33.7 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-image==0.19.3 in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
      "Collecting PyWavelets==1.4.1\n",
      "  Downloading PyWavelets-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.3) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/work/.local/lib/python3.10/site-packages (from matplotlib==3.6.3) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.3) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/work/.local/lib/python3.10/site-packages (from matplotlib==3.6.3) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.3) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/work/.local/lib/python3.10/site-packages (from matplotlib==3.6.3) (7.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/work/.local/lib/python3.10/site-packages (from matplotlib==3.6.3) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/work/.local/lib/python3.10/site-packages (from matplotlib==3.6.3) (2.8.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/work/.local/lib/python3.10/site-packages (from scikit-image==0.19.3) (2.5)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/work/.local/lib/python3.10/site-packages (from scikit-image==0.19.3) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/work/.local/lib/python3.10/site-packages (from scikit-image==0.19.3) (2020.9.3)\n",
      "Requirement already satisfied: six in /home/work/.local/lib/python3.10/site-packages (from cycler>=0.10->matplotlib==3.6.3) (1.15.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from networkx>=2.2->scikit-image==0.19.3) (4.4.2)\n",
      "Installing collected packages: scipy, PyWavelets, matplotlib\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lida 0.0.10 requires fastapi, which is not installed.\n",
      "lida 0.0.10 requires kaleido, which is not installed.\n",
      "lida 0.0.10 requires python-multipart, which is not installed.\n",
      "lida 0.0.10 requires uvicorn, which is not installed.\n",
      "bigframes 0.16.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.0.2 which is incompatible.\n",
      "fastai 2.7.13 requires pillow>=9.0.0, but you have pillow 7.2.0 which is incompatible.\n",
      "imbalanced-learn 0.10.1 requires joblib>=1.1.1, but you have joblib 0.16.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyWavelets-1.4.1 matplotlib-3.6.3 scipy-1.9.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "matplotlib",
         "mpl_toolkits"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install --no-cache-dir \\\n",
    "    numpy==1.23.5 \\\n",
    "    matplotlib==3.6.3 \\\n",
    "    scipy==1.9.3 \\\n",
    "    scikit-image==0.19.3 \\\n",
    "    PyWavelets==1.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files removed: 71\n"
     ]
    }
   ],
   "source": [
    "!pip cache purge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 1.11.0\n",
      "Uninstalling torch-1.11.0:\n",
      "  Successfully uninstalled torch-1.11.0\n",
      "Found existing installation: torchvision 0.12.0\n",
      "Uninstalling torchvision-0.12.0:\n",
      "  Successfully uninstalled torchvision-0.12.0\n",
      "Found existing installation: torchaudio 2.1.0+cu121\n",
      "Uninstalling torchaudio-2.1.0+cu121:\n",
      "\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/shutil.py\", line 816, in move\n",
      "    os.rename(src, real_dst)\n",
      "PermissionError: [Errno 13] Permission denied: '/usr/local/lib/python3.10/dist-packages/torchaudio-2.1.0+cu121.dist-info/' -> '/tmp/pip-uninstall-93eni1ff'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/uninstall.py\", line 105, in run\n",
      "    uninstall_pathset = req.uninstall(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/req/req_install.py\", line 680, in uninstall\n",
      "    uninstalled_pathset.remove(auto_confirm, verbose)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/req/req_uninstall.py\", line 381, in remove\n",
      "    moved.stash(path)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/req/req_uninstall.py\", line 272, in stash\n",
      "    renames(path, new_path)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/misc.py\", line 313, in renames\n",
      "    shutil.move(old, new)\n",
      "  File \"/usr/lib/python3.10/shutil.py\", line 834, in move\n",
      "    rmtree(src)\n",
      "  File \"/usr/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/usr/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/usr/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "PermissionError: [Errno 13] Permission denied: 'RECORD'\u001b[0m\u001b[31m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch==2.1.0+cu118\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.1.0%2Bcu118-cp310-cp310-linux_x86_64.whl (2325.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m983.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hCollecting torchvision==0.16.0+cu118\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.16.0%2Bcu118-cp310-cp310-linux_x86_64.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torchaudio==2.1.0 in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu118) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu118) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu118) (1.12)\n",
      "Requirement already satisfied: networkx in /home/work/.local/lib/python3.10/site-packages (from torch==2.1.0+cu118) (2.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu118) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu118) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu118) (2.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0+cu118) (1.23.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0+cu118) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/work/.local/lib/python3.10/site-packages (from torchvision==0.16.0+cu118) (7.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0+cu118) (2.1.3)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from networkx->torch==2.1.0+cu118) (4.4.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0+cu118) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0+cu118) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0+cu118) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/work/.local/lib/python3.10/site-packages (from requests->torchvision==0.16.0+cu118) (2020.6.20)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0+cu118) (1.3.0)\n",
      "Installing collected packages: torch, torchvision\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastai 2.7.13 requires pillow>=9.0.0, but you have pillow 7.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.1.0+cu118 torchvision-0.16.0+cu118\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall torch torchvision torchaudio -y\n",
    "\n",
    "!pip install torch==2.1.0+cu118 torchvision==0.16.0+cu118 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using distributed mode\n",
      "Start training: epochs=50, batch_size=16, lr=0.0005\n",
      "start train :0\n",
      "100% 28/28 [00:12<00:00,  2.20it/s]\n",
      "[Epoch 0] val_acc=0.547 val_auc=0.473 val_loss=5.567\n",
      "✔ best.pth updated\n",
      "train loss: [6.928]\n",
      "val loss: [5.567]\n",
      "train acc: [0.158]\n",
      "val acc: [0.547]\n",
      "train CE loss [0.0]\n",
      "val CE loss [5.567]\n",
      "train attention loss [0.0]\n",
      "val attention loss [0.0]\n",
      "start train :1\n",
      "100% 28/28 [00:09<00:00,  2.86it/s]\n",
      "[Epoch 1] val_acc=0.432 val_auc=0.491 val_loss=6.559\n",
      "train loss: [6.928, 6.48]\n",
      "val loss: [5.567, 6.559]\n",
      "train acc: [0.158, 0.435]\n",
      "val acc: [0.547, 0.432]\n",
      "train CE loss [0.0, 0.0]\n",
      "val CE loss [5.567, 6.559]\n",
      "train attention loss [0.0, 0.0]\n",
      "val attention loss [0.0, 0.0]\n",
      "start train :2\n",
      "100% 28/28 [00:09<00:00,  2.84it/s]\n",
      "[Epoch 2] val_acc=0.537 val_auc=0.499 val_loss=6.559\n",
      "train loss: [6.928, 6.48, 6.305]\n",
      "val loss: [5.567, 6.559, 6.559]\n",
      "train acc: [0.158, 0.435, 0.562]\n",
      "val acc: [0.547, 0.432, 0.537]\n",
      "train CE loss [0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559]\n",
      "train attention loss [0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0]\n",
      "start train :3\n",
      "100% 28/28 [00:10<00:00,  2.79it/s]\n",
      "[Epoch 3] val_acc=0.505 val_auc=0.557 val_loss=6.677\n",
      "train loss: [6.928, 6.48, 6.305, 6.202]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0]\n",
      "start train :4\n",
      "100% 28/28 [00:10<00:00,  2.75it/s]\n",
      "[Epoch 4] val_acc=0.600 val_auc=0.521 val_loss=6.295\n",
      "Epoch 00005: reducing learning rate of group 0 to 2.5000e-04.\n",
      "✔ best.pth updated\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :5\n",
      "100% 28/28 [00:11<00:00,  2.38it/s]\n",
      "[Epoch 5] val_acc=0.505 val_auc=0.502 val_loss=6.613\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :6\n",
      "100% 28/28 [00:10<00:00,  2.70it/s]\n",
      "[Epoch 6] val_acc=0.558 val_auc=0.580 val_loss=6.337\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :7\n",
      "100% 28/28 [00:11<00:00,  2.44it/s]\n",
      "[Epoch 7] val_acc=0.547 val_auc=0.580 val_loss=6.454\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :8\n",
      "100% 28/28 [00:09<00:00,  2.83it/s]\n",
      "[Epoch 8] val_acc=0.642 val_auc=0.646 val_loss=6.254\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.2500e-04.\n",
      "✔ best.pth updated\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774, 5.727]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77, 0.777]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547, 0.642]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :9\n",
      "100% 28/28 [00:10<00:00,  2.71it/s]\n",
      "[Epoch 9] val_acc=0.589 val_auc=0.597 val_loss=6.336\n",
      "→ saved checkpoint: checkpoint_0009.pth\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774, 5.727, 5.68]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77, 0.777, 0.804]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547, 0.642, 0.589]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :10\n",
      "100% 28/28 [00:10<00:00,  2.66it/s]\n",
      "[Epoch 10] val_acc=0.568 val_auc=0.612 val_loss=6.324\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774, 5.727, 5.68, 5.567]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77, 0.777, 0.804, 0.859]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547, 0.642, 0.589, 0.568]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :11\n",
      "100% 28/28 [00:09<00:00,  2.85it/s]\n",
      "[Epoch 11] val_acc=0.653 val_auc=0.618 val_loss=6.318\n",
      "✔ best.pth updated\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774, 5.727, 5.68, 5.567, 5.559]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77, 0.777, 0.804, 0.859, 0.85]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547, 0.642, 0.589, 0.568, 0.653]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :12\n",
      "100% 28/28 [00:09<00:00,  2.90it/s]\n",
      "[Epoch 12] val_acc=0.632 val_auc=0.625 val_loss=6.279\n",
      "Epoch 00013: reducing learning rate of group 0 to 6.2500e-05.\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774, 5.727, 5.68, 5.567, 5.559, 5.467]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77, 0.777, 0.804, 0.859, 0.85, 0.886]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547, 0.642, 0.589, 0.568, 0.653, 0.632]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :13\n",
      "100% 28/28 [00:11<00:00,  2.40it/s]\n",
      "[Epoch 13] val_acc=0.642 val_auc=0.633 val_loss=6.166\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774, 5.727, 5.68, 5.567, 5.559, 5.467, 5.43]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77, 0.777, 0.804, 0.859, 0.85, 0.886, 0.904]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547, 0.642, 0.589, 0.568, 0.653, 0.632, 0.642]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :14\n",
      "100% 28/28 [00:09<00:00,  2.80it/s]\n",
      "[Epoch 14] val_acc=0.653 val_auc=0.631 val_loss=6.215\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774, 5.727, 5.68, 5.567, 5.559, 5.467, 5.43, 5.462]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77, 0.777, 0.804, 0.859, 0.85, 0.886, 0.904, 0.9]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547, 0.642, 0.589, 0.568, 0.653, 0.632, 0.642, 0.653]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :15\n",
      "100% 28/28 [00:09<00:00,  2.84it/s]\n",
      "[Epoch 15] val_acc=0.663 val_auc=0.662 val_loss=6.179\n",
      "✔ best.pth updated\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774, 5.727, 5.68, 5.567, 5.559, 5.467, 5.43, 5.462, 5.434]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215, 6.179]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77, 0.777, 0.804, 0.859, 0.85, 0.886, 0.904, 0.9, 0.895]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547, 0.642, 0.589, 0.568, 0.653, 0.632, 0.642, 0.653, 0.663]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215, 6.179]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :16\n",
      "100% 28/28 [00:10<00:00,  2.77it/s]\n",
      "[Epoch 16] val_acc=0.674 val_auc=0.671 val_loss=6.134\n",
      "Epoch 00017: reducing learning rate of group 0 to 3.1250e-05.\n",
      "✔ best.pth updated\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774, 5.727, 5.68, 5.567, 5.559, 5.467, 5.43, 5.462, 5.434, 5.39]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215, 6.179, 6.134]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77, 0.777, 0.804, 0.859, 0.85, 0.886, 0.904, 0.9, 0.895, 0.924]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547, 0.642, 0.589, 0.568, 0.653, 0.632, 0.642, 0.653, 0.663, 0.674]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215, 6.179, 6.134]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :17\n",
      "100% 28/28 [00:09<00:00,  2.87it/s]\n",
      "[Epoch 17] val_acc=0.705 val_auc=0.680 val_loss=6.093\n",
      "✔ best.pth updated\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774, 5.727, 5.68, 5.567, 5.559, 5.467, 5.43, 5.462, 5.434, 5.39, 5.38]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215, 6.179, 6.134, 6.093]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77, 0.777, 0.804, 0.859, 0.85, 0.886, 0.904, 0.9, 0.895, 0.924, 0.933]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547, 0.642, 0.589, 0.568, 0.653, 0.632, 0.642, 0.653, 0.663, 0.674, 0.705]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215, 6.179, 6.134, 6.093]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :18\n",
      "100% 28/28 [00:10<00:00,  2.79it/s]\n",
      "[Epoch 18] val_acc=0.695 val_auc=0.675 val_loss=6.025\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774, 5.727, 5.68, 5.567, 5.559, 5.467, 5.43, 5.462, 5.434, 5.39, 5.38, 5.36]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215, 6.179, 6.134, 6.093, 6.025]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77, 0.777, 0.804, 0.859, 0.85, 0.886, 0.904, 0.9, 0.895, 0.924, 0.933, 0.94]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547, 0.642, 0.589, 0.568, 0.653, 0.632, 0.642, 0.653, 0.663, 0.674, 0.705, 0.695]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215, 6.179, 6.134, 6.093, 6.025]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :19\n",
      "100% 28/28 [00:11<00:00,  2.37it/s]\n",
      "[Epoch 19] val_acc=0.684 val_auc=0.665 val_loss=6.044\n",
      "→ saved checkpoint: checkpoint_0019.pth\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774, 5.727, 5.68, 5.567, 5.559, 5.467, 5.43, 5.462, 5.434, 5.39, 5.38, 5.36, 5.35]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215, 6.179, 6.134, 6.093, 6.025, 6.044]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77, 0.777, 0.804, 0.859, 0.85, 0.886, 0.904, 0.9, 0.895, 0.924, 0.933, 0.94, 0.942]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547, 0.642, 0.589, 0.568, 0.653, 0.632, 0.642, 0.653, 0.663, 0.674, 0.705, 0.695, 0.684]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215, 6.179, 6.134, 6.093, 6.025, 6.044]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :20\n",
      "100% 28/28 [00:09<00:00,  2.84it/s]\n",
      "[Epoch 20] val_acc=0.674 val_auc=0.663 val_loss=6.001\n",
      "Epoch 00021: reducing learning rate of group 0 to 1.5625e-05.\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774, 5.727, 5.68, 5.567, 5.559, 5.467, 5.43, 5.462, 5.434, 5.39, 5.38, 5.36, 5.35, 5.389]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215, 6.179, 6.134, 6.093, 6.025, 6.044, 6.001]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77, 0.777, 0.804, 0.859, 0.85, 0.886, 0.904, 0.9, 0.895, 0.924, 0.933, 0.94, 0.942, 0.917]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547, 0.642, 0.589, 0.568, 0.653, 0.632, 0.642, 0.653, 0.663, 0.674, 0.705, 0.695, 0.684, 0.674]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215, 6.179, 6.134, 6.093, 6.025, 6.044, 6.001]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :21\n",
      "100% 28/28 [00:10<00:00,  2.73it/s]\n",
      "[Epoch 21] val_acc=0.663 val_auc=0.644 val_loss=6.042\n",
      "train loss: [6.928, 6.48, 6.305, 6.202, 6.076, 5.961, 5.851, 5.774, 5.727, 5.68, 5.567, 5.559, 5.467, 5.43, 5.462, 5.434, 5.39, 5.38, 5.36, 5.35, 5.389, 5.339]\n",
      "val loss: [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215, 6.179, 6.134, 6.093, 6.025, 6.044, 6.001, 6.042]\n",
      "train acc: [0.158, 0.435, 0.562, 0.603, 0.652, 0.703, 0.763, 0.77, 0.777, 0.804, 0.859, 0.85, 0.886, 0.904, 0.9, 0.895, 0.924, 0.933, 0.94, 0.942, 0.917, 0.924]\n",
      "val acc: [0.547, 0.432, 0.537, 0.505, 0.6, 0.505, 0.558, 0.547, 0.642, 0.589, 0.568, 0.653, 0.632, 0.642, 0.653, 0.663, 0.674, 0.705, 0.695, 0.684, 0.674, 0.663]\n",
      "train CE loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val CE loss [5.567, 6.559, 6.559, 6.677, 6.295, 6.613, 6.337, 6.454, 6.254, 6.336, 6.324, 6.318, 6.279, 6.166, 6.215, 6.179, 6.134, 6.093, 6.025, 6.044, 6.001, 6.042]\n",
      "train attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "val attention loss [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "start train :22\n",
      "100% 28/28 [00:10<00:00,  2.71it/s]\n",
      "[Epoch 22] val_acc=0.674 val_auc=0.663 val_loss=6.081\n",
      "Early-Stopping at epoch 22 (no val_acc ↑ for 5 epochs)\n",
      "Total training time: 0:04:56\n"
     ]
    }
   ],
   "source": [
    "# baseline\n",
    "!python train.py --dataset Blastocyst \\\n",
    "    --model resnest26d \\\n",
    "    --batch_size 16 \\\n",
    "    --epochs 50 \\\n",
    "    --num_classes 2 \\\n",
    "    --aug true \\\n",
    "    --lr 0.0005 \\\n",
    "    --vis false \\\n",
    "    --weight_decay 0.005 \\\n",
    "    --use_slot false \\\n",
    "    --channel 3 \\\n",
    "    --use_pre true \\\n",
    "    --freeze_layers 3 \\\n",
    "    --dataset_dir /home/work/SCOUTERv2/scouter/data/blastocyst/split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using distributed mode\n",
      "Resume from /home/work/SCOUTERv2/scouter/saved_model/best5.pth → backbone만 로드, 학습은 처음부터 이어서 진행합니다.\n",
      "Start training: epochs=30, batch_size=16, lr=0.0001\n",
      "start train :0\n",
      "100% 28/28 [00:11<00:00,  2.43it/s]\n",
      "[Epoch 0] val_acc=0.589 val_auc=0.698 val_loss=1.511\n",
      "✔ best.pth updated\n",
      "train loss: [0.944]\n",
      "val loss: [1.511]\n",
      "train acc: [0.589]\n",
      "val acc: [0.589]\n",
      "train CE loss [0.569]\n",
      "val CE loss [1.229]\n",
      "train attention loss [0.187]\n",
      "val attention loss [0.141]\n",
      "start train :1\n",
      "100% 28/28 [00:09<00:00,  2.94it/s]\n",
      "[Epoch 1] val_acc=0.547 val_auc=0.583 val_loss=1.176\n",
      "train loss: [0.944, 0.792]\n",
      "val loss: [1.511, 1.176]\n",
      "train acc: [0.589, 0.759]\n",
      "val acc: [0.589, 0.547]\n",
      "train CE loss [0.569, 0.529]\n",
      "val CE loss [1.229, 0.93]\n",
      "train attention loss [0.187, 0.131]\n",
      "val attention loss [0.141, 0.123]\n",
      "start train :2\n",
      "100% 28/28 [00:09<00:00,  2.98it/s]\n",
      "[Epoch 2] val_acc=0.568 val_auc=0.558 val_loss=1.098\n",
      "train loss: [0.944, 0.792, 0.57]\n",
      "val loss: [1.511, 1.176, 1.098]\n",
      "train acc: [0.589, 0.759, 0.857]\n",
      "val acc: [0.589, 0.547, 0.568]\n",
      "train CE loss [0.569, 0.529, 0.376]\n",
      "val CE loss [1.229, 0.93, 0.923]\n",
      "train attention loss [0.187, 0.131, 0.097]\n",
      "val attention loss [0.141, 0.123, 0.087]\n",
      "start train :3\n",
      "100% 28/28 [00:10<00:00,  2.76it/s]\n",
      "[Epoch 3] val_acc=0.621 val_auc=0.641 val_loss=1.372\n",
      "✔ best.pth updated\n",
      "train loss: [0.944, 0.792, 0.57, 0.473]\n",
      "val loss: [1.511, 1.176, 1.098, 1.372]\n",
      "train acc: [0.589, 0.759, 0.857, 0.857]\n",
      "val acc: [0.589, 0.547, 0.568, 0.621]\n",
      "train CE loss [0.569, 0.529, 0.376, 0.352]\n",
      "val CE loss [1.229, 0.93, 0.923, 1.284]\n",
      "train attention loss [0.187, 0.131, 0.097, 0.06]\n",
      "val attention loss [0.141, 0.123, 0.087, 0.044]\n",
      "start train :4\n",
      "100% 28/28 [00:09<00:00,  2.99it/s]\n",
      "[Epoch 4] val_acc=0.632 val_auc=0.663 val_loss=1.192\n",
      "✔ best.pth updated\n",
      "train loss: [0.944, 0.792, 0.57, 0.473, 0.326]\n",
      "val loss: [1.511, 1.176, 1.098, 1.372, 1.192]\n",
      "train acc: [0.589, 0.759, 0.857, 0.857, 0.908]\n",
      "val acc: [0.589, 0.547, 0.568, 0.621, 0.632]\n",
      "train CE loss [0.569, 0.529, 0.376, 0.352, 0.256]\n",
      "val CE loss [1.229, 0.93, 0.923, 1.284, 1.135]\n",
      "train attention loss [0.187, 0.131, 0.097, 0.06, 0.035]\n",
      "val attention loss [0.141, 0.123, 0.087, 0.044, 0.028]\n",
      "start train :5\n",
      "100% 28/28 [00:09<00:00,  2.90it/s]\n",
      "[Epoch 5] val_acc=0.579 val_auc=0.592 val_loss=1.067\n",
      "train loss: [0.944, 0.792, 0.57, 0.473, 0.326, 0.29]\n",
      "val loss: [1.511, 1.176, 1.098, 1.372, 1.192, 1.067]\n",
      "train acc: [0.589, 0.759, 0.857, 0.857, 0.908, 0.906]\n",
      "val acc: [0.589, 0.547, 0.568, 0.621, 0.632, 0.579]\n",
      "train CE loss [0.569, 0.529, 0.376, 0.352, 0.256, 0.249]\n",
      "val CE loss [1.229, 0.93, 0.923, 1.284, 1.135, 1.025]\n",
      "train attention loss [0.187, 0.131, 0.097, 0.06, 0.035, 0.021]\n",
      "val attention loss [0.141, 0.123, 0.087, 0.044, 0.028, 0.021]\n",
      "start train :6\n",
      "100% 28/28 [00:09<00:00,  2.98it/s]\n",
      "[Epoch 6] val_acc=0.621 val_auc=0.638 val_loss=1.687\n",
      "train loss: [0.944, 0.792, 0.57, 0.473, 0.326, 0.29, 0.182]\n",
      "val loss: [1.511, 1.176, 1.098, 1.372, 1.192, 1.067, 1.687]\n",
      "train acc: [0.589, 0.759, 0.857, 0.857, 0.908, 0.906, 0.955]\n",
      "val acc: [0.589, 0.547, 0.568, 0.621, 0.632, 0.579, 0.621]\n",
      "train CE loss [0.569, 0.529, 0.376, 0.352, 0.256, 0.249, 0.152]\n",
      "val CE loss [1.229, 0.93, 0.923, 1.284, 1.135, 1.025, 1.659]\n",
      "train attention loss [0.187, 0.131, 0.097, 0.06, 0.035, 0.021, 0.015]\n",
      "val attention loss [0.141, 0.123, 0.087, 0.044, 0.028, 0.021, 0.014]\n",
      "start train :7\n",
      "100% 28/28 [00:09<00:00,  2.94it/s]\n",
      "[Epoch 7] val_acc=0.642 val_auc=0.592 val_loss=1.117\n",
      "✔ best.pth updated\n",
      "train loss: [0.944, 0.792, 0.57, 0.473, 0.326, 0.29, 0.182, 0.254]\n",
      "val loss: [1.511, 1.176, 1.098, 1.372, 1.192, 1.067, 1.687, 1.117]\n",
      "train acc: [0.589, 0.759, 0.857, 0.857, 0.908, 0.906, 0.955, 0.911]\n",
      "val acc: [0.589, 0.547, 0.568, 0.621, 0.632, 0.579, 0.621, 0.642]\n",
      "train CE loss [0.569, 0.529, 0.376, 0.352, 0.256, 0.249, 0.152, 0.236]\n",
      "val CE loss [1.229, 0.93, 0.923, 1.284, 1.135, 1.025, 1.659, 1.099]\n",
      "train attention loss [0.187, 0.131, 0.097, 0.06, 0.035, 0.021, 0.015, 0.009]\n",
      "val attention loss [0.141, 0.123, 0.087, 0.044, 0.028, 0.021, 0.014, 0.009]\n",
      "start train :8\n",
      "100% 28/28 [00:09<00:00,  2.97it/s]\n",
      "[Epoch 8] val_acc=0.516 val_auc=0.522 val_loss=1.822\n",
      "train loss: [0.944, 0.792, 0.57, 0.473, 0.326, 0.29, 0.182, 0.254, 0.137]\n",
      "val loss: [1.511, 1.176, 1.098, 1.372, 1.192, 1.067, 1.687, 1.117, 1.822]\n",
      "train acc: [0.589, 0.759, 0.857, 0.857, 0.908, 0.906, 0.955, 0.911, 0.938]\n",
      "val acc: [0.589, 0.547, 0.568, 0.621, 0.632, 0.579, 0.621, 0.642, 0.516]\n",
      "train CE loss [0.569, 0.529, 0.376, 0.352, 0.256, 0.249, 0.152, 0.236, 0.124]\n",
      "val CE loss [1.229, 0.93, 0.923, 1.284, 1.135, 1.025, 1.659, 1.099, 1.807]\n",
      "train attention loss [0.187, 0.131, 0.097, 0.06, 0.035, 0.021, 0.015, 0.009, 0.006]\n",
      "val attention loss [0.141, 0.123, 0.087, 0.044, 0.028, 0.021, 0.014, 0.009, 0.007]\n",
      "start train :9\n",
      "100% 28/28 [00:09<00:00,  2.96it/s]\n",
      "[Epoch 9] val_acc=0.642 val_auc=0.674 val_loss=1.327\n",
      "Epoch 00010: reducing learning rate of group 0 to 5.0000e-05.\n",
      "→ saved checkpoint: checkpoint_0009.pth\n",
      "train loss: [0.944, 0.792, 0.57, 0.473, 0.326, 0.29, 0.182, 0.254, 0.137, 0.235]\n",
      "val loss: [1.511, 1.176, 1.098, 1.372, 1.192, 1.067, 1.687, 1.117, 1.822, 1.327]\n",
      "train acc: [0.589, 0.759, 0.857, 0.857, 0.908, 0.906, 0.955, 0.911, 0.938, 0.92]\n",
      "val acc: [0.589, 0.547, 0.568, 0.621, 0.632, 0.579, 0.621, 0.642, 0.516, 0.642]\n",
      "train CE loss [0.569, 0.529, 0.376, 0.352, 0.256, 0.249, 0.152, 0.236, 0.124, 0.226]\n",
      "val CE loss [1.229, 0.93, 0.923, 1.284, 1.135, 1.025, 1.659, 1.099, 1.807, 1.319]\n",
      "train attention loss [0.187, 0.131, 0.097, 0.06, 0.035, 0.021, 0.015, 0.009, 0.006, 0.004]\n",
      "val attention loss [0.141, 0.123, 0.087, 0.044, 0.028, 0.021, 0.014, 0.009, 0.007, 0.004]\n",
      "start train :10\n",
      "100% 28/28 [00:09<00:00,  2.88it/s]\n",
      "[Epoch 10] val_acc=0.621 val_auc=0.628 val_loss=1.102\n",
      "train loss: [0.944, 0.792, 0.57, 0.473, 0.326, 0.29, 0.182, 0.254, 0.137, 0.235, 0.186]\n",
      "val loss: [1.511, 1.176, 1.098, 1.372, 1.192, 1.067, 1.687, 1.117, 1.822, 1.327, 1.102]\n",
      "train acc: [0.589, 0.759, 0.857, 0.857, 0.908, 0.906, 0.955, 0.911, 0.938, 0.92, 0.94]\n",
      "val acc: [0.589, 0.547, 0.568, 0.621, 0.632, 0.579, 0.621, 0.642, 0.516, 0.642, 0.621]\n",
      "train CE loss [0.569, 0.529, 0.376, 0.352, 0.256, 0.249, 0.152, 0.236, 0.124, 0.226, 0.179]\n",
      "val CE loss [1.229, 0.93, 0.923, 1.284, 1.135, 1.025, 1.659, 1.099, 1.807, 1.319, 1.092]\n",
      "train attention loss [0.187, 0.131, 0.097, 0.06, 0.035, 0.021, 0.015, 0.009, 0.006, 0.004, 0.004]\n",
      "val attention loss [0.141, 0.123, 0.087, 0.044, 0.028, 0.021, 0.014, 0.009, 0.007, 0.004, 0.005]\n",
      "start train :11\n",
      "100% 28/28 [00:09<00:00,  2.94it/s]\n",
      "[Epoch 11] val_acc=0.684 val_auc=0.660 val_loss=0.984\n",
      "✔ best.pth updated\n",
      "train loss: [0.944, 0.792, 0.57, 0.473, 0.326, 0.29, 0.182, 0.254, 0.137, 0.235, 0.186, 0.149]\n",
      "val loss: [1.511, 1.176, 1.098, 1.372, 1.192, 1.067, 1.687, 1.117, 1.822, 1.327, 1.102, 0.984]\n",
      "train acc: [0.589, 0.759, 0.857, 0.857, 0.908, 0.906, 0.955, 0.911, 0.938, 0.92, 0.94, 0.946]\n",
      "val acc: [0.589, 0.547, 0.568, 0.621, 0.632, 0.579, 0.621, 0.642, 0.516, 0.642, 0.621, 0.684]\n",
      "train CE loss [0.569, 0.529, 0.376, 0.352, 0.256, 0.249, 0.152, 0.236, 0.124, 0.226, 0.179, 0.143]\n",
      "val CE loss [1.229, 0.93, 0.923, 1.284, 1.135, 1.025, 1.659, 1.099, 1.807, 1.319, 1.092, 0.974]\n",
      "train attention loss [0.187, 0.131, 0.097, 0.06, 0.035, 0.021, 0.015, 0.009, 0.006, 0.004, 0.004, 0.003]\n",
      "val attention loss [0.141, 0.123, 0.087, 0.044, 0.028, 0.021, 0.014, 0.009, 0.007, 0.004, 0.005, 0.005]\n",
      "start train :12\n",
      "100% 28/28 [00:09<00:00,  2.94it/s]\n",
      "[Epoch 12] val_acc=0.653 val_auc=0.640 val_loss=1.247\n",
      "train loss: [0.944, 0.792, 0.57, 0.473, 0.326, 0.29, 0.182, 0.254, 0.137, 0.235, 0.186, 0.149, 0.097]\n",
      "val loss: [1.511, 1.176, 1.098, 1.372, 1.192, 1.067, 1.687, 1.117, 1.822, 1.327, 1.102, 0.984, 1.247]\n",
      "train acc: [0.589, 0.759, 0.857, 0.857, 0.908, 0.906, 0.955, 0.911, 0.938, 0.92, 0.94, 0.946, 0.969]\n",
      "val acc: [0.589, 0.547, 0.568, 0.621, 0.632, 0.579, 0.621, 0.642, 0.516, 0.642, 0.621, 0.684, 0.653]\n",
      "train CE loss [0.569, 0.529, 0.376, 0.352, 0.256, 0.249, 0.152, 0.236, 0.124, 0.226, 0.179, 0.143, 0.091]\n",
      "val CE loss [1.229, 0.93, 0.923, 1.284, 1.135, 1.025, 1.659, 1.099, 1.807, 1.319, 1.092, 0.974, 1.239]\n",
      "train attention loss [0.187, 0.131, 0.097, 0.06, 0.035, 0.021, 0.015, 0.009, 0.006, 0.004, 0.004, 0.003, 0.003]\n",
      "val attention loss [0.141, 0.123, 0.087, 0.044, 0.028, 0.021, 0.014, 0.009, 0.007, 0.004, 0.005, 0.005, 0.004]\n",
      "start train :13\n",
      "100% 28/28 [00:09<00:00,  2.97it/s]\n",
      "[Epoch 13] val_acc=0.611 val_auc=0.616 val_loss=1.129\n",
      "train loss: [0.944, 0.792, 0.57, 0.473, 0.326, 0.29, 0.182, 0.254, 0.137, 0.235, 0.186, 0.149, 0.097, 0.137]\n",
      "val loss: [1.511, 1.176, 1.098, 1.372, 1.192, 1.067, 1.687, 1.117, 1.822, 1.327, 1.102, 0.984, 1.247, 1.129]\n",
      "train acc: [0.589, 0.759, 0.857, 0.857, 0.908, 0.906, 0.955, 0.911, 0.938, 0.92, 0.94, 0.946, 0.969, 0.951]\n",
      "val acc: [0.589, 0.547, 0.568, 0.621, 0.632, 0.579, 0.621, 0.642, 0.516, 0.642, 0.621, 0.684, 0.653, 0.611]\n",
      "train CE loss [0.569, 0.529, 0.376, 0.352, 0.256, 0.249, 0.152, 0.236, 0.124, 0.226, 0.179, 0.143, 0.091, 0.133]\n",
      "val CE loss [1.229, 0.93, 0.923, 1.284, 1.135, 1.025, 1.659, 1.099, 1.807, 1.319, 1.092, 0.974, 1.239, 1.121]\n",
      "train attention loss [0.187, 0.131, 0.097, 0.06, 0.035, 0.021, 0.015, 0.009, 0.006, 0.004, 0.004, 0.003, 0.003, 0.002]\n",
      "val attention loss [0.141, 0.123, 0.087, 0.044, 0.028, 0.021, 0.014, 0.009, 0.007, 0.004, 0.005, 0.005, 0.004, 0.004]\n",
      "start train :14\n",
      "100% 28/28 [00:09<00:00,  2.93it/s]\n",
      "[Epoch 14] val_acc=0.621 val_auc=0.619 val_loss=1.238\n",
      "train loss: [0.944, 0.792, 0.57, 0.473, 0.326, 0.29, 0.182, 0.254, 0.137, 0.235, 0.186, 0.149, 0.097, 0.137, 0.063]\n",
      "val loss: [1.511, 1.176, 1.098, 1.372, 1.192, 1.067, 1.687, 1.117, 1.822, 1.327, 1.102, 0.984, 1.247, 1.129, 1.238]\n",
      "train acc: [0.589, 0.759, 0.857, 0.857, 0.908, 0.906, 0.955, 0.911, 0.938, 0.92, 0.94, 0.946, 0.969, 0.951, 0.978]\n",
      "val acc: [0.589, 0.547, 0.568, 0.621, 0.632, 0.579, 0.621, 0.642, 0.516, 0.642, 0.621, 0.684, 0.653, 0.611, 0.621]\n",
      "train CE loss [0.569, 0.529, 0.376, 0.352, 0.256, 0.249, 0.152, 0.236, 0.124, 0.226, 0.179, 0.143, 0.091, 0.133, 0.059]\n",
      "val CE loss [1.229, 0.93, 0.923, 1.284, 1.135, 1.025, 1.659, 1.099, 1.807, 1.319, 1.092, 0.974, 1.239, 1.121, 1.231]\n",
      "train attention loss [0.187, 0.131, 0.097, 0.06, 0.035, 0.021, 0.015, 0.009, 0.006, 0.004, 0.004, 0.003, 0.003, 0.002, 0.002]\n",
      "val attention loss [0.141, 0.123, 0.087, 0.044, 0.028, 0.021, 0.014, 0.009, 0.007, 0.004, 0.005, 0.005, 0.004, 0.004, 0.003]\n",
      "start train :15\n",
      "100% 28/28 [00:09<00:00,  2.89it/s]\n",
      "[Epoch 15] val_acc=0.568 val_auc=0.585 val_loss=1.441\n",
      "Epoch 00016: reducing learning rate of group 0 to 2.5000e-05.\n",
      "train loss: [0.944, 0.792, 0.57, 0.473, 0.326, 0.29, 0.182, 0.254, 0.137, 0.235, 0.186, 0.149, 0.097, 0.137, 0.063, 0.06]\n",
      "val loss: [1.511, 1.176, 1.098, 1.372, 1.192, 1.067, 1.687, 1.117, 1.822, 1.327, 1.102, 0.984, 1.247, 1.129, 1.238, 1.441]\n",
      "train acc: [0.589, 0.759, 0.857, 0.857, 0.908, 0.906, 0.955, 0.911, 0.938, 0.92, 0.94, 0.946, 0.969, 0.951, 0.978, 0.98]\n",
      "val acc: [0.589, 0.547, 0.568, 0.621, 0.632, 0.579, 0.621, 0.642, 0.516, 0.642, 0.621, 0.684, 0.653, 0.611, 0.621, 0.568]\n",
      "train CE loss [0.569, 0.529, 0.376, 0.352, 0.256, 0.249, 0.152, 0.236, 0.124, 0.226, 0.179, 0.143, 0.091, 0.133, 0.059, 0.057]\n",
      "val CE loss [1.229, 0.93, 0.923, 1.284, 1.135, 1.025, 1.659, 1.099, 1.807, 1.319, 1.092, 0.974, 1.239, 1.121, 1.231, 1.435]\n",
      "train attention loss [0.187, 0.131, 0.097, 0.06, 0.035, 0.021, 0.015, 0.009, 0.006, 0.004, 0.004, 0.003, 0.003, 0.002, 0.002, 0.002]\n",
      "val attention loss [0.141, 0.123, 0.087, 0.044, 0.028, 0.021, 0.014, 0.009, 0.007, 0.004, 0.005, 0.005, 0.004, 0.004, 0.003, 0.003]\n",
      "start train :16\n",
      "100% 28/28 [00:09<00:00,  2.82it/s]\n",
      "[Epoch 16] val_acc=0.621 val_auc=0.630 val_loss=1.300\n",
      "Early-Stopping at epoch 16 (no val_acc ↑ for 5 epochs)\n",
      "Total training time: 0:03:24\n"
     ]
    }
   ],
   "source": [
    "# slot-positive\n",
    "!python train_slot.py \\\n",
    "  --dataset Blastocyst \\\n",
    "  --model resnest26d \\\n",
    "  --batch_size 16 \\\n",
    "  --epochs 30 \\\n",
    "  --num_classes 2 \\\n",
    "  --use_slot true \\\n",
    "  --use_pre false \\\n",
    "  --loss_status 1 \\\n",
    "  --slots_per_class 1 \\\n",
    "  --power 2 \\\n",
    "  --to_k_layer 3 \\\n",
    "  --lambda_value 2.0 \\\n",
    "  --vis false \\\n",
    "  --freeze_layers 1 \\\n",
    "  --resume /home/work/SCOUTERv2/scouter/saved_model/best5.pth \\\n",
    "  --dataset_dir /home/work/SCOUTERv2/scouter/data/blastocyst/split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using distributed mode\n",
      "Resume from /home/work/SCOUTERv2/scouter/saved_model/best5.pth → backbone만 로드, 학습은 처음부터 이어서 진행합니다.\n",
      "Start training: epochs=30, batch_size=16, lr=0.0001\n",
      "start train :0\n",
      "100% 28/28 [00:11<00:00,  2.47it/s]\n",
      "[Epoch 0] val_acc=0.589 val_auc=0.583 val_loss=1.999\n",
      "✔ best.pth updated\n",
      "train loss: [0.68]\n",
      "val loss: [1.999]\n",
      "train acc: [0.766]\n",
      "val acc: [0.589]\n",
      "train CE loss [0.582]\n",
      "val CE loss [1.914]\n",
      "train attention loss [0.197]\n",
      "val attention loss [0.169]\n",
      "start train :1\n",
      "100% 28/28 [00:09<00:00,  2.95it/s]\n",
      "[Epoch 1] val_acc=0.642 val_auc=0.663 val_loss=2.271\n",
      "✔ best.pth updated\n",
      "train loss: [0.68, 0.511]\n",
      "val loss: [1.999, 2.271]\n",
      "train acc: [0.766, 0.817]\n",
      "val acc: [0.589, 0.642]\n",
      "train CE loss [0.582, 0.43]\n",
      "val CE loss [1.914, 2.197]\n",
      "train attention loss [0.197, 0.162]\n",
      "val attention loss [0.169, 0.147]\n",
      "start train :2\n",
      "100% 28/28 [00:09<00:00,  2.99it/s]\n",
      "[Epoch 2] val_acc=0.653 val_auc=0.589 val_loss=1.220\n",
      "✔ best.pth updated\n",
      "train loss: [0.68, 0.511, 0.415]\n",
      "val loss: [1.999, 2.271, 1.22]\n",
      "train acc: [0.766, 0.817, 0.862]\n",
      "val acc: [0.589, 0.642, 0.653]\n",
      "train CE loss [0.582, 0.43, 0.347]\n",
      "val CE loss [1.914, 2.197, 1.158]\n",
      "train attention loss [0.197, 0.162, 0.137]\n",
      "val attention loss [0.169, 0.147, 0.125]\n",
      "start train :3\n",
      "100% 28/28 [00:09<00:00,  2.94it/s]\n",
      "[Epoch 3] val_acc=0.547 val_auc=0.521 val_loss=1.690\n",
      "train loss: [0.68, 0.511, 0.415, 0.349]\n",
      "val loss: [1.999, 2.271, 1.22, 1.69]\n",
      "train acc: [0.766, 0.817, 0.862, 0.897]\n",
      "val acc: [0.589, 0.642, 0.653, 0.547]\n",
      "train CE loss [0.582, 0.43, 0.347, 0.29]\n",
      "val CE loss [1.914, 2.197, 1.158, 1.635]\n",
      "train attention loss [0.197, 0.162, 0.137, 0.118]\n",
      "val attention loss [0.169, 0.147, 0.125, 0.11]\n",
      "start train :4\n",
      "100% 28/28 [00:09<00:00,  2.94it/s]\n",
      "[Epoch 4] val_acc=0.611 val_auc=0.683 val_loss=0.794\n",
      "train loss: [0.68, 0.511, 0.415, 0.349, 0.329]\n",
      "val loss: [1.999, 2.271, 1.22, 1.69, 0.794]\n",
      "train acc: [0.766, 0.817, 0.862, 0.897, 0.886]\n",
      "val acc: [0.589, 0.642, 0.653, 0.547, 0.611]\n",
      "train CE loss [0.582, 0.43, 0.347, 0.29, 0.277]\n",
      "val CE loss [1.914, 2.197, 1.158, 1.635, 0.747]\n",
      "train attention loss [0.197, 0.162, 0.137, 0.118, 0.104]\n",
      "val attention loss [0.169, 0.147, 0.125, 0.11, 0.093]\n",
      "start train :5\n",
      "100% 28/28 [00:09<00:00,  2.96it/s]\n",
      "[Epoch 5] val_acc=0.632 val_auc=0.636 val_loss=1.171\n",
      "train loss: [0.68, 0.511, 0.415, 0.349, 0.329, 0.285]\n",
      "val loss: [1.999, 2.271, 1.22, 1.69, 0.794, 1.171]\n",
      "train acc: [0.766, 0.817, 0.862, 0.897, 0.886, 0.92]\n",
      "val acc: [0.589, 0.642, 0.653, 0.547, 0.611, 0.632]\n",
      "train CE loss [0.582, 0.43, 0.347, 0.29, 0.277, 0.241]\n",
      "val CE loss [1.914, 2.197, 1.158, 1.635, 0.747, 1.132]\n",
      "train attention loss [0.197, 0.162, 0.137, 0.118, 0.104, 0.087]\n",
      "val attention loss [0.169, 0.147, 0.125, 0.11, 0.093, 0.078]\n",
      "start train :6\n",
      "100% 28/28 [00:09<00:00,  2.99it/s]\n",
      "[Epoch 6] val_acc=0.568 val_auc=0.555 val_loss=1.975\n",
      "train loss: [0.68, 0.511, 0.415, 0.349, 0.329, 0.285, 0.159]\n",
      "val loss: [1.999, 2.271, 1.22, 1.69, 0.794, 1.171, 1.975]\n",
      "train acc: [0.766, 0.817, 0.862, 0.897, 0.886, 0.92, 0.955]\n",
      "val acc: [0.589, 0.642, 0.653, 0.547, 0.611, 0.632, 0.568]\n",
      "train CE loss [0.582, 0.43, 0.347, 0.29, 0.277, 0.241, 0.121]\n",
      "val CE loss [1.914, 2.197, 1.158, 1.635, 0.747, 1.132, 1.938]\n",
      "train attention loss [0.197, 0.162, 0.137, 0.118, 0.104, 0.087, 0.075]\n",
      "val attention loss [0.169, 0.147, 0.125, 0.11, 0.093, 0.078, 0.074]\n",
      "start train :7\n",
      "100% 28/28 [00:09<00:00,  2.94it/s]\n",
      "[Epoch 7] val_acc=0.579 val_auc=0.588 val_loss=0.862\n",
      "Early-Stopping at epoch 7 (no val_acc ↑ for 5 epochs)\n",
      "Total training time: 0:01:36\n"
     ]
    }
   ],
   "source": [
    "# slot-negative\n",
    "!python train_slot.py \\\n",
    "  --dataset Blastocyst \\\n",
    "  --model resnest26d \\\n",
    "  --batch_size 16 \\\n",
    "  --epochs 30 \\\n",
    "  --num_classes 2 \\\n",
    "  --use_slot true \\\n",
    "  --use_pre false \\\n",
    "  --loss_status -1 \\\n",
    "  --slots_per_class 1 \\\n",
    "  --power 2 \\\n",
    "  --to_k_layer 3 \\\n",
    "  --lambda_value 0.5 \\\n",
    "  --lr 0.0001 \\\n",
    "  --vis false \\\n",
    "  --freeze_layers 1 \\\n",
    "  --resume /home/work/SCOUTERv2/scouter/saved_model/best5.pth \\\n",
    "  --dataset_dir /home/work/SCOUTERv2/scouter/data/blastocyst/split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground-truth label:\t 1\n",
      "Checkpoint keys: ['model', 'optimizer', 'lr_scheduler', 'epoch', 'args', 'best_acc']\n",
      "Raw logits: [-0.45084488 -1.0135995 ]\n",
      "Predicted class: 0\n"
     ]
    }
   ],
   "source": [
    "!python test.py \\\n",
    "  --dataset Blastocyst \\\n",
    "  --model resnest26d \\\n",
    "  --batch_size 16 \\\n",
    "  --num_classes 2 \\\n",
    "  --use_slot true \\\n",
    "  --use_pre false \\\n",
    "  --loss_status -1 \\\n",
    "  --slots_per_class 1 \\\n",
    "  --power 2 \\\n",
    "  --to_k_layer 3 \\\n",
    "  --lambda_value 1 \\\n",
    "  --vis true \\\n",
    "  --freeze_layers 0 \\\n",
    "  --dataset_dir /home/work/SCOUTERv2/scouter/data/blastocyst/split \\\n",
    "  --output_dir saved_model/best1p-slot.pth"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] generating explanation images …\n",
      "Predicting labels: 100% 1/1 [00:00<00:00,  1.18it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 155.32it/s]\n",
      "Inserting pixels: 100% 261/261 [00:05<00:00, 46.52it/s]\n",
      "AUC: 0.6496361165522383\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 60.30it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 87.64it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:05<00:00, 50.57it/s]\n",
      "AUC: 0.5259455373689819\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 57.91it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 288.70it/s]\n",
      "Inserting pixels: 100% 261/261 [00:05<00:00, 48.50it/s]\n",
      "AUC: 0.6722101455894657\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 45.01it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 51.19it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:05<00:00, 49.91it/s]\n",
      "AUC: 0.5298551982698533\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 49.29it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 260.77it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 54.30it/s]\n",
      "AUC: 0.6153237577814322\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 57.52it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 73.47it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 53.25it/s]\n",
      "AUC: 0.5383982658601151\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 62.89it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 308.18it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 54.80it/s]\n",
      "AUC: 0.7606284817096401\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 58.62it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 729.06it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:05<00:00, 49.37it/s]\n",
      "AUC: 0.5776379936088163\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 44.60it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 315.96it/s]\n",
      "Inserting pixels: 100% 261/261 [00:05<00:00, 51.93it/s]\n",
      "AUC: 0.7191809269026495\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 60.42it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 594.94it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 54.61it/s]\n",
      "AUC: 0.5699946799709533\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 52.43it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 292.35it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 52.29it/s]\n",
      "AUC: 0.7192733676817554\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 61.04it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 54.97it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:05<00:00, 51.33it/s]\n",
      "AUC: 0.5086026008778181\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 52.05it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 303.12it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 54.11it/s]\n",
      "AUC: 0.6336185967191481\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 70.11it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 1064.27it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 54.89it/s]\n",
      "AUC: 0.551217518804165\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 54.05it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 119.38it/s]\n",
      "Inserting pixels: 100% 261/261 [00:05<00:00, 49.53it/s]\n",
      "AUC: 0.5628506087053281\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 54.75it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 1244.23it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:05<00:00, 48.08it/s]\n",
      "AUC: 0.5975770346462154\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 56.73it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 301.71it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 54.18it/s]\n",
      "AUC: 0.5021567066916479\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 60.52it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 52.65it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:05<00:00, 49.67it/s]\n",
      "AUC: 0.5277413273409296\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 59.16it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 308.06it/s]\n",
      "Inserting pixels: 100% 261/261 [00:05<00:00, 44.40it/s]\n",
      "AUC: 0.5240908270200285\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 40.48it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 1216.80it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 53.39it/s]\n",
      "AUC: 0.5042628713408843\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 69.55it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 327.32it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 52.78it/s]\n",
      "AUC: 0.5717598678114323\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 52.67it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 1215.39it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 52.34it/s]\n",
      "AUC: 0.6777251024900649\n",
      "Predicting labels: 100% 1/1 [00:00<00:00,  5.46it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 176.97it/s]\n",
      "Inserting pixels: 100% 261/261 [00:04<00:00, 54.58it/s]\n",
      "AUC: 0.6583154789939687\n",
      "Predicting labels: 100% 1/1 [00:00<00:00, 61.71it/s]\n",
      "Substrate: 100% 1/1 [00:00<00:00, 1135.13it/s]\n",
      "Deleting  pixels: 100% 261/261 [00:04<00:00, 54.24it/s]\n",
      "AUC: 0.655511975272592\n",
      "IAUC=0.6324 | DAUC=0.5637\n",
      "Infidelity=0.0033 | Sensitivity=1.9692\n",
      "Infidelity per pert: {'Gaussian': 0.0032818089912579067}\n",
      "Sensitivity per pert: {'Gaussian': 1.9692473192649809}\n"
     ]
    }
   ],
   "source": [
    "!python eval_blasto.py \\\n",
    "  --dataset_dir /home/work/SCOUTERv2/scouter/data/blastocyst/split \\\n",
    "  --checkpoint  /home/work/SCOUTERv2/scouter/saved_model/best2n-slot.pth \\\n",
    "  --model resnest26d \\\n",
    "  --use_slot true \\\n",
    "  --pre_trained true \\\n",
    "  --loss_status -1 \\\n",
    "  --to_k_layer 3 \\\n",
    "  --lambda_value 1 \\\n",
    "  --freeze_layers 0 \\\n",
    "  --vis true \\\n",
    "  --auc --saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from /home/work/SCOUTERv2/scouter/saved_model/best2n-slot.pth\n",
      "{'auc': 0.34598214285714285, 'accuracy': 0.203125, 'precision': 0.10909090909090909, 'recall': 0.75, 'f1': 0.19047619047619047, 'kappa': -0.035532994923857864}\n"
     ]
    }
   ],
   "source": [
    "!python confusion_matrix_metrics.py \\\n",
    "  --dataset Blastocyst \\\n",
    "  --checkpoint /home/work/SCOUTERv2/scouter/saved_model/best2n-slot.pth \\\n",
    "  --dataset_dir /home/work/SCOUTERv2/scouter/data/blastocyst/split \\\n",
    "  --model resnest26d \\\n",
    "  --use_slot true \\\n",
    "  --pre_trained true \\\n",
    "  --loss_status 1 \\\n",
    "  --to_k_layer 3 \\\n",
    "  --lambda_value 1 \\\n",
    "  --slots_per_class 1 \\\n",
    "  --power 2 \\\n",
    "  --freeze_layers 0 \\\n",
    "  --output_dir saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from /home/work/SCOUTERv2/scouter/saved_model/best4.pth\n",
      "⚠️  load_state_dict 경고:\n",
      "   누락된 파라미터: ['conv1x1.weight', 'slot.initial_slots', 'slot.to_q.0.weight', 'slot.to_q.0.bias', 'slot.to_k.0.weight', 'slot.to_k.0.bias', 'slot.gru.weight_ih_l0', 'slot.gru.weight_hh_l0', 'slot.gru.bias_ih_l0', 'slot.gru.bias_hh_l0']\n",
      "   예기치 않은 파라미터: ['backbone.fc.weight', 'backbone.fc.bias']\n",
      "{'auc': 0.65625, 'accuracy': 0.515625, 'precision': 0.17142857142857143, 'recall': 0.75, 'f1': 0.2790697674418604, 'kappa': 0.0948905109489051}\n"
     ]
    }
   ],
   "source": [
    "!python confusion_matrix_metrics.py \\\n",
    "  --dataset Blastocyst \\\n",
    "  --checkpoint /home/work/SCOUTERv2/scouter/saved_model/best4.pth \\\n",
    "  --dataset_dir /home/work/SCOUTERv2/scouter/data/blastocyst/split \\\n",
    "  --model resnest26d \\\n",
    "  --pre_trained true \\\n",
    "  --freeze_layers 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
